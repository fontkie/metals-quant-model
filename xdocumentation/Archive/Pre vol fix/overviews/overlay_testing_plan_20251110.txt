# OVERLAY TESTING PLAN - Complete Validation Framework
## Three-Layer Adaptive System with Priority Hierarchy

**Document Purpose:** Systematic testing protocol for ChopCore, TightnessCore (Extreme Override), and CrisisCore v2 overlays  
**Target Audience:** Quantitative systematic trading team  
**Timeline:** 4-week validation cycle  
**Created:** November 10, 2025  
**Version:** 1.0

---

## ðŸ“‹ TABLE OF CONTENTS

1. [Executive Summary](#executive-summary)
2. [System Architecture Verification](#system-architecture-verification)
3. [Phase 1: Individual Overlay Validation](#phase-1-individual-overlay-validation)
4. [Phase 2: Combined System Validation](#phase-2-combined-system-validation)
5. [Phase 3: Robustness Testing](#phase-3-robustness-testing)
6. [Phase 4: Anti-Bias Safeguards](#phase-4-anti-bias-safeguards)
7. [Acceptance Criteria](#acceptance-criteria)
8. [Code Structure](#code-structure)
9. [Execution Timeline](#execution-timeline)
10. [Appendix: Historical Event Catalog](#appendix-historical-event-catalog)

---

## EXECUTIVE SUMMARY

### System Overview

We are testing a **three-layer adaptive portfolio system** for copper systematic trading:

**Layer 1: Base Sleeves**
- TrendCore v3 (60-day trend follower)
- TrendImpulse v4 (20-day momentum)
- MomentumCore v1 (intermediate momentum)
- Current combined Sharpe: **0.767** (25 years)

**Layer 2: Adaptive Regime Blending**
- Nine market regime buckets (volatility Ã— trend state)
- Dynamic sleeve weights based on regime-specific performance
- 20.1% improvement over static allocation

**Layer 3: Three Overlays with Priority Hierarchy**
- **Priority 1:** Extreme Tightness Override (>80 or <20)
- **Priority 2:** ChopCore (macro confusion detector)
- **Priority 3:** CrisisCore v2 (directional amplification)

### Testing Objectives

1. **Validate each overlay works independently** before combining
2. **Confirm priority hierarchy logic** prevents conflicts
3. **Stress test robustness** against overfitting and parameter sensitivity
4. **Apply anti-bias safeguards** including out-of-sample metals testing
5. **Achieve target:** 0.80-0.85 Sharpe ratio (from current 0.767)

### Key Success Metrics

- ChopCore improves Sharpe by **+0.04-0.05** in choppy regimes
- Extreme Tightness Override amplifies correctly during supply shocks
- CrisisCore v2 provides directional amplification when no chop present
- Combined system passes all robustness tests (parameter sensitivity, walk-forward)
- System logic generalizes to aluminum (out-of-sample metal test)

---

## SYSTEM ARCHITECTURE VERIFICATION

### Three-Layer Structure

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LAYER 1: BASE SLEEVES                                   â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                               â”‚
â”‚ â€¢ TrendCore v3 (60-day)                                 â”‚
â”‚ â€¢ TrendImpulse v4 (20-day)                              â”‚
â”‚ â€¢ MomentumCore v1 (40-day)                              â”‚
â”‚ Output: Individual position signals                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LAYER 2: ADAPTIVE REGIME PORTFOLIO                      â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                     â”‚
â”‚ â€¢ Nine regime buckets (vol Ã— trend)                     â”‚
â”‚ â€¢ Dynamic sleeve weights per regime                     â”‚
â”‚ â€¢ Regime-stratified optimization                        â”‚
â”‚ Output: Base position (e.g., 0.8Ã— long)                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LAYER 3: THREE OVERLAYS (Priority Hierarchy)            â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€       â”‚
â”‚                                                          â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ PRIORITY 1: EXTREME TIGHTNESS OVERRIDE             â”‚ â”‚
â”‚ â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€            â”‚ â”‚
â”‚ â”‚ Trigger: Tightness >80 or <20                      â”‚ â”‚
â”‚ â”‚ Effect: Overrides BOTH ChopCore AND CrisisCore     â”‚ â”‚
â”‚ â”‚ Action: 1.5Ã— directional amplification             â”‚ â”‚
â”‚ â”‚ Example: Grasberg strike (tight=95) â†’ 1.5Ã— bullish â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                          â†“                               â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ PRIORITY 2: CHOPCORE (Macro Confusion)             â”‚ â”‚
â”‚ â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                â”‚ â”‚
â”‚ â”‚ Trigger: Only if tightness 20-80 (not extreme)     â”‚ â”‚
â”‚ â”‚ Effect: Overrides CrisisCore directional logic     â”‚ â”‚
â”‚ â”‚ Action: Reduce size (HIGH_CHOP=0.5Ã—, MILD=0.75Ã—)   â”‚ â”‚
â”‚ â”‚ Example: 2018 trade war â†’ 0.5Ã— reduction           â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                          â†“                               â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ PRIORITY 3: CRISISCORE V2 (Directional)            â”‚ â”‚
â”‚ â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€               â”‚ â”‚
â”‚ â”‚ Trigger: Only if chop=NORMAL and tightness 20-80   â”‚ â”‚
â”‚ â”‚ Effect: Directional amplification                  â”‚ â”‚
â”‚ â”‚ Logic:                                             â”‚ â”‚
â”‚ â”‚   â€¢ Crisis + Tight â†’ Amplify bullish (1.3Ã—)        â”‚ â”‚
â”‚ â”‚   â€¢ Crisis + Loose â†’ Amplify bearish (1.3Ã—)        â”‚ â”‚
â”‚ â”‚   â€¢ Crisis + Neutral â†’ Mixed (0.8-1.0Ã—)            â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                          â”‚
â”‚ Output: Final position (e.g., 0.8 Ã— 0.5 = 0.4Ã— from    â”‚
â”‚         base 0.8Ã— reduced by HIGH_CHOP 0.5Ã— multiplier) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Critical Architecture Properties

#### âœ… Mutual Exclusivity Rules

1. **ChopCore and CrisisCore Directional NEVER fire simultaneously**
   - If ChopCore active (HIGH_CHOP or MILD_CHOP) â†’ CrisisCore blocked
   - If CrisisCore active â†’ Requires chop=NORMAL
   - This prevents conflicting signals

2. **Extreme Tightness CAN overlap with ChopCore**
   - But Extreme Tightness takes priority
   - ChopCore reduction is "lightened" (0.75Ã— instead of 0.5Ã— for HIGH_CHOP)
   - Ensures fundamentals override technical chop signals

#### âš™ï¸ Priority Hierarchy Logic

```python
def determine_final_position(base_position, chop_regime, crisis_regime, tightness_score):
    """
    Priority Hierarchy Implementation
    """
    
    # PRIORITY 1: Extreme Fundamentals Override
    if tightness_score > 80:  # Extreme tight
        chop_mult = 0.75 if chop_regime == 'HIGH_CHOP' else 0.9
        position_after_chop = base_position * chop_mult
        
        if position_after_chop > 0:
            final_position = position_after_chop * 1.5  # Amplify bullish
        else:
            final_position = position_after_chop * 0.5  # Dampen conflicting bearish
            
        return final_position, 'EXTREME_TIGHT_OVERRIDE'
    
    elif tightness_score < 20:  # Extreme loose
        chop_mult = 0.75 if chop_regime == 'HIGH_CHOP' else 0.9
        position_after_chop = base_position * chop_mult
        
        if position_after_chop < 0:
            final_position = position_after_chop * 1.5  # Amplify bearish
        else:
            final_position = position_after_chop * 0.5  # Dampen conflicting bullish
            
        return final_position, 'EXTREME_LOOSE_OVERRIDE'
    
    # PRIORITY 2: ChopCore Override (Normal Fundamentals 20-80)
    elif chop_regime in ['HIGH_CHOP', 'MILD_CHOP']:
        chop_mult = 0.5 if chop_regime == 'HIGH_CHOP' else 0.75
        final_position = base_position * chop_mult
        # CrisisCore directional is BLOCKED
        return final_position, f'CHOP_OVERRIDE_{chop_regime}'
    
    # PRIORITY 3: CrisisCore v2 Directional (No Chop, Normal Fundamentals)
    else:  # chop_regime == 'NORMAL' and tightness 20-80
        crisis_mult = calculate_crisis_directional(
            crisis_regime, tightness_score, base_position
        )
        final_position = base_position * crisis_mult
        return final_position, 'CRISIS_TIGHTNESS_DIRECTIONAL'
```

### Configuration Parameters

```yaml
# Extreme Fundamental Thresholds
extreme_tight_threshold: 80    # >80 = fundamentals override everything
extreme_loose_threshold: 20    # <20 = fundamentals override everything

# Tight/Loose Thresholds (Normal Operation)
tight_threshold: 70            # Considered "tight" but not extreme
loose_threshold: 40            # Considered "loose" but not extreme

# ChopCore Thresholds
high_chop_threshold: 0.55      # >0.55 = HIGH_CHOP regime
mild_chop_threshold: 0.35      # 0.35-0.55 = MILD_CHOP regime

# ChopCore Multipliers (Standard)
chop_mult_high: 0.50          # 50% size in HIGH_CHOP
chop_mult_mild: 0.75          # 75% size in MILD_CHOP

# ChopCore Multipliers (With Extreme Fundamentals)
chop_mult_high_with_extreme: 0.75   # Lighter reduction
chop_mult_mild_with_extreme: 0.90   # Very light reduction

# CrisisCore Directional Multipliers
crisis_tight_amplify: 1.3      # Crisis + tight fundamentals
crisis_loose_amplify: 1.3      # Crisis + loose fundamentals
crisis_neutral_reduce: 0.8     # Crisis + neutral fundamentals
```

---

## PHASE 1: INDIVIDUAL OVERLAY VALIDATION

**Objective:** Test each overlay independently to isolate effects and prove individual value-add

**Duration:** Week 1

**Philosophy:** Renaissance principle - validate components work alone before combining them

### Test 1A: ChopCore Overlay (Standalone)

#### Purpose
Validate that ChopCore correctly identifies macro confusion periods and improves performance by reducing size during directionless markets.

#### Baseline Setup

```python
# Baseline: Adaptive portfolio WITHOUT any overlays
baseline_config = {
    'sleeves': ['TrendCore_v3', 'TrendImpulse_v4', 'MomentumCore_v1'],
    'adaptive_blending': True,
    'overlays': None  # NO overlays
}

baseline_results = run_backtest(baseline_config)
baseline_sharpe = baseline_results['sharpe']
baseline_drawdown = baseline_results['max_drawdown']
```

#### Test Setup

```python
# Test: Apply ONLY ChopCore overlay
test_config = {
    'sleeves': ['TrendCore_v3', 'TrendImpulse_v4', 'MomentumCore_v1'],
    'adaptive_blending': True,
    'overlays': ['ChopCore']  # ONLY ChopCore
}

test_results = run_backtest(test_config)
test_sharpe = test_results['sharpe']
test_drawdown = test_results['max_drawdown']
```

#### Metrics to Capture

**Overall Performance:**
```python
metrics = {
    'sharpe_improvement': test_sharpe - baseline_sharpe,
    'drawdown_change': test_drawdown - baseline_drawdown,
    'total_return_change': test_return - baseline_return,
    'win_rate': test_win_rate,
    'avg_trade_duration': days
}

# Target: Sharpe improvement +0.004 to +0.05 overall
# (Small overall because chop is only ~15-20% of time)
```

**Regime-Specific Performance (CRITICAL!):**
```python
regime_analysis = {
    'HIGH_CHOP': {
        'baseline_sharpe': baseline_sharpe_in_high_chop,
        'test_sharpe': test_sharpe_in_high_chop,
        'improvement': test_sharpe - baseline_sharpe,
        'days': number_of_high_chop_days
    },
    'MILD_CHOP': {
        'baseline_sharpe': baseline_sharpe_in_mild_chop,
        'test_sharpe': test_sharpe_in_mild_chop,
        'improvement': test_sharpe - baseline_sharpe,
        'days': number_of_mild_chop_days
    },
    'NORMAL': {
        'baseline_sharpe': baseline_sharpe_in_normal,
        'test_sharpe': test_sharpe_in_normal,
        'improvement': test_sharpe - baseline_sharpe,
        'days': number_of_normal_days
    },
    'TRENDING': {
        'baseline_sharpe': baseline_sharpe_in_trending,
        'test_sharpe': test_sharpe_in_trending,
        'improvement': test_sharpe - baseline_sharpe,
        'days': number_of_trending_days
    }
}
```

#### Validation Tests

```python
# TEST 1: Does ChopCore help in chop regimes?
assert regime_analysis['HIGH_CHOP']['improvement'] > 0.04, \
    "ChopCore should improve HIGH_CHOP Sharpe by >0.04"

assert regime_analysis['MILD_CHOP']['improvement'] > 0.02, \
    "ChopCore should improve MILD_CHOP Sharpe by >0.02"

# TEST 2: Does ChopCore hurt trending regimes?
assert regime_analysis['TRENDING']['improvement'] > -0.05, \
    "ChopCore should not hurt TRENDING regimes significantly"

# TEST 3: Is ChopCore neutral in NORMAL regimes?
assert abs(regime_analysis['NORMAL']['improvement']) < 0.02, \
    "ChopCore should be neutral in NORMAL regimes"
```

#### Historical Event Validation

```python
# Expected ChopCore triggers during known choppy periods
expected_chop_events = [
    {
        'period': '2018-03-01 to 2018-11-30',  # Trade war range
        'regime': 'HIGH_CHOP',
        'reason': 'Trade war uncertainty, macro opposing forces',
        'expected_sizing': 0.5  # 50% reduction
    },
    {
        'period': '2015-06-01 to 2016-03-31',  # China slowdown range
        'regime': 'MILD_CHOP to HIGH_CHOP',
        'reason': 'China slowdown fears, commodity range-bound',
        'expected_sizing': 0.5-0.75
    },
    {
        'period': '2011-08-01 to 2011-12-31',  # US debt ceiling
        'regime': 'MILD_CHOP',
        'reason': 'US debt ceiling drama, European debt crisis',
        'expected_sizing': 0.75
    }
]

# For each event:
for event in expected_chop_events:
    actual_chop_regime = get_chop_regime(event['period'])
    actual_sizing = get_chop_sizing(event['period'])
    
    assert actual_chop_regime == event['regime'], \
        f"ChopCore failed to detect {event['period']}: {event['reason']}"
    
    assert abs(actual_sizing - event['expected_sizing']) < 0.1, \
        f"ChopCore sizing incorrect for {event['period']}"
```

#### Output Report

```markdown
# ChopCore Standalone Test Results

## Overall Metrics
- Baseline Sharpe: 0.767
- Test Sharpe: 0.771
- Improvement: +0.004 (+0.5%)

## Regime-Specific Performance
| Regime      | Baseline Sharpe | Test Sharpe | Improvement | Days  |
|-------------|-----------------|-------------|-------------|-------|
| HIGH_CHOP   | -0.23           | +0.02       | **+0.25**   | 387   |
| MILD_CHOP   | +0.15           | +0.20       | **+0.05**   | 521   |
| NORMAL      | +0.82           | +0.81       | -0.01       | 4,892 |
| TRENDING    | +1.15           | +1.14       | -0.01       | 1,200 |

## Historical Event Validation
âœ… 2018 Trade War: HIGH_CHOP detected, 0.5Ã— sizing applied
âœ… 2015-2016 Range: MILD_CHOP detected, 0.75Ã— sizing applied
âœ… 2011 Debt Ceiling: MILD_CHOP detected, 0.75Ã— sizing applied

## Conclusion
ChopCore works as intended:
- Improves HIGH_CHOP by +0.25 Sharpe (target: >0.04) âœ…
- Improves MILD_CHOP by +0.05 Sharpe (target: >0.02) âœ…
- Neutral in trending markets (-0.01 Sharpe) âœ…
- Overall modest improvement (+0.004) appropriate given regime frequency

**PASS: Proceed to Test 1B**
```

---

### Test 1B: Extreme Tightness Override (Standalone)

#### Purpose
Validate that extreme fundamental conditions (tightness >80 or <20) correctly amplify positions directionally and override technical signals.

#### Baseline Setup

```python
# Baseline: Adaptive portfolio WITHOUT any overlays
baseline_config = {
    'sleeves': ['TrendCore_v3', 'TrendImpulse_v4', 'MomentumCore_v1'],
    'adaptive_blending': True,
    'overlays': None
}

baseline_results = run_backtest(baseline_config)
```

#### Test Setup

```python
# Test: Apply ONLY Extreme Tightness Override (Priority 1)
test_config = {
    'sleeves': ['TrendCore_v3', 'TrendImpulse_v4', 'MomentumCore_v1'],
    'adaptive_blending': True,
    'overlays': ['ExtremeTightnessOverride']  # ONLY Priority 1
}

# Ignore ChopCore and CrisisCore completely
test_results = run_backtest(test_config)
```

#### Metrics to Capture

**Trigger Frequency:**
```python
trigger_analysis = {
    'extreme_tight_days': count_days_tightness_gt_80,
    'extreme_loose_days': count_days_tightness_lt_20,
    'total_extreme_days': extreme_tight_days + extreme_loose_days,
    'extreme_frequency': total_extreme_days / total_days,
    'expected_frequency': 0.03  # ~3% of time
}

# Validate frequency is reasonable (not too rare or too common)
assert 0.02 < trigger_analysis['extreme_frequency'] < 0.05, \
    "Extreme events should occur 2-5% of time"
```

**Performance During Extreme Periods:**
```python
extreme_performance = {
    'extreme_tight': {
        'baseline_sharpe': baseline_sharpe_when_tight_gt_80,
        'test_sharpe': test_sharpe_when_tight_gt_80,
        'improvement': test_sharpe - baseline_sharpe,
        'amplification_applied': mean_amplification_multiplier
    },
    'extreme_loose': {
        'baseline_sharpe': baseline_sharpe_when_tight_lt_20,
        'test_sharpe': test_sharpe_when_tight_lt_20,
        'improvement': test_sharpe - baseline_sharpe,
        'amplification_applied': mean_amplification_multiplier
    }
}

# Target: Improvement during extreme periods
# (Amplifying winning positions should increase Sharpe)
```

#### Historical Event Validation

```python
# Known extreme tightness events (>80)
extreme_tight_events = [
    {
        'date': '2006-06-01',
        'event': 'Grasberg strike begins',
        'expected_tightness': 85,
        'expected_amplification': 1.5,
        'base_position': 0.8,  # Bullish trend
        'expected_final_position': 1.2  # 0.8 Ã— 1.5
    },
    {
        'date': '2010-11-15',
        'event': 'Codelco mine closures',
        'expected_tightness': 82,
        'expected_amplification': 1.5,
        'base_position': 0.6,
        'expected_final_position': 0.9
    },
    {
        'date': '2021-05-01',
        'event': 'Chile supply squeeze',
        'expected_tightness': 87,
        'expected_amplification': 1.5,
        'base_position': 1.0,
        'expected_final_position': 1.5
    }
]

# Known extreme looseness events (<20)
extreme_loose_events = [
    {
        'date': '2008-10-15',
        'event': 'GFC demand collapse',
        'expected_tightness': 12,
        'expected_amplification': 1.5,
        'base_position': -0.9,  # Bearish trend
        'expected_final_position': -1.35  # -0.9 Ã— 1.5
    },
    {
        'date': '2015-08-01',
        'event': 'China slowdown, inventory buildup',
        'expected_tightness': 18,
        'expected_amplification': 1.5,
        'base_position': -0.5,
        'expected_final_position': -0.75
    }
]

# Test each event
for event in extreme_tight_events:
    actual_tightness = get_tightness_score(event['date'])
    actual_amplification = get_amplification_multiplier(event['date'])
    actual_final_position = get_final_position(event['date'])
    
    assert actual_tightness > 80, \
        f"Tightness should be >80 for {event['event']}"
    
    assert abs(actual_amplification - event['expected_amplification']) < 0.2, \
        f"Amplification incorrect for {event['event']}"
    
    assert abs(actual_final_position - event['expected_final_position']) < 0.2, \
        f"Final position incorrect for {event['event']}"

for event in extreme_loose_events:
    actual_tightness = get_tightness_score(event['date'])
    actual_amplification = get_amplification_multiplier(event['date'])
    actual_final_position = get_final_position(event['date'])
    
    assert actual_tightness < 20, \
        f"Tightness should be <20 for {event['event']}"
    
    assert abs(actual_amplification - event['expected_amplification']) < 0.2, \
        f"Amplification incorrect for {event['event']}"
    
    assert abs(actual_final_position - event['expected_final_position']) < 0.2, \
        f"Final position incorrect for {event['event']}"
```

#### Directional Alignment Test

```python
# Test that amplification aligns with fundamentals
directional_test = {
    'extreme_tight_bullish': {
        'condition': 'tightness >80 AND base_position >0',
        'expected_action': 'Amplify bullish (1.5Ã—)',
        'reason': 'Supply shock supports bullish trend'
    },
    'extreme_tight_bearish': {
        'condition': 'tightness >80 AND base_position <0',
        'expected_action': 'Dampen bearish (0.5Ã—)',
        'reason': 'Bearish trend conflicts with tight fundamentals'
    },
    'extreme_loose_bearish': {
        'condition': 'tightness <20 AND base_position <0',
        'expected_action': 'Amplify bearish (1.5Ã—)',
        'reason': 'Demand destruction supports bearish trend'
    },
    'extreme_loose_bullish': {
        'condition': 'tightness <20 AND base_position >0',
        'expected_action': 'Dampen bullish (0.5Ã—)',
        'reason': 'Bullish trend conflicts with loose fundamentals'
    }
}

# For each scenario, verify logic works correctly
for scenario, details in directional_test.items():
    test_cases = get_test_cases_matching_condition(details['condition'])
    
    for test_case in test_cases:
        actual_multiplier = test_case['crisis_mult']
        
        if 'Amplify' in details['expected_action']:
            assert actual_multiplier == 1.5, \
                f"Should amplify in {scenario}"
        elif 'Dampen' in details['expected_action']:
            assert actual_multiplier == 0.5, \
                f"Should dampen in {scenario}"
```

#### Output Report

```markdown
# Extreme Tightness Override Standalone Test Results

## Trigger Frequency
- Extreme tight days (>80): 87 days (1.4%)
- Extreme loose days (<20): 64 days (1.0%)
- Total extreme days: 151 days (2.4%)
- âœ… Within expected range (2-5%)

## Performance During Extreme Periods
| Condition      | Baseline Sharpe | Test Sharpe | Improvement | Amplification |
|----------------|-----------------|-------------|-------------|---------------|
| Extreme Tight  | +0.85           | +1.12       | **+0.27**   | 1.47Ã—         |
| Extreme Loose  | +0.42           | +0.58       | **+0.16**   | 1.45Ã—         |

## Historical Event Validation
âœ… 2006 Grasberg Strike: Tightness=85, amplified 1.5Ã—
âœ… 2010 Codelco Closures: Tightness=82, amplified 1.5Ã—
âœ… 2021 Chile Squeeze: Tightness=87, amplified 1.5Ã—
âœ… 2008 GFC: Tightness=12, amplified bearish 1.5Ã—
âœ… 2015 China Slowdown: Tightness=18, amplified bearish 1.5Ã—

## Directional Alignment
âœ… Tight + Bullish â†’ Amplify (100% correct)
âœ… Tight + Bearish â†’ Dampen (100% correct)
âœ… Loose + Bearish â†’ Amplify (100% correct)
âœ… Loose + Bullish â†’ Dampen (100% correct)

## Conclusion
Extreme Tightness Override works as intended:
- Triggers at appropriate frequency (2.4% of time) âœ…
- Improves Sharpe during extreme periods âœ…
- Historical events detected correctly âœ…
- Directional logic aligns with fundamentals âœ…

**PASS: Proceed to Test 1C**
```

---

### Test 1C: CrisisCore v2 Directional (Standalone)

#### Purpose
Validate that CrisisCore v2 provides appropriate directional amplification based on crisis regime + tightness alignment, WITHOUT defensive position cutting.

#### Baseline Setup

```python
# Baseline: Adaptive portfolio WITHOUT any overlays
baseline_config = {
    'sleeves': ['TrendCore_v3', 'TrendImpulse_v4', 'MomentumCore_v1'],
    'adaptive_blending': True,
    'overlays': None
}

baseline_results = run_backtest(baseline_config)
```

#### Test Setup

```python
# Test: Apply ONLY CrisisCore v2 Directional
# IMPORTANT: Assume chop=NORMAL so CrisisCore can fire
test_config = {
    'sleeves': ['TrendCore_v3', 'TrendImpulse_v4', 'MomentumCore_v1'],
    'adaptive_blending': True,
    'overlays': ['CrisisCoreV2Directional']  # ONLY Priority 3
}

# For this test, force chop_regime = 'NORMAL' globally
# (We test chop blocking separately in Phase 2)
test_results = run_backtest(test_config, force_chop_normal=True)
```

#### Metrics to Capture

**Crisis Regime Frequency:**
```python
crisis_frequency = {
    'CRISIS': count_crisis_days / total_days,
    'PRE_CRISIS': count_pre_crisis_days / total_days,
    'STRESS': count_stress_days / total_days,
    'NORMAL': count_normal_days / total_days
}

# Expected frequencies based on historical data:
# CRISIS: ~3-5% of time
# PRE_CRISIS: ~5-8% of time
# STRESS: ~10-15% of time
```

**Performance by Crisis + Tightness Combination:**
```python
scenario_performance = {
    'crisis_tight': {
        'description': 'Crisis regime + tight fundamentals (>70)',
        'expected_behavior': 'Amplify bullish positions',
        'baseline_sharpe': baseline_sharpe_crisis_tight,
        'test_sharpe': test_sharpe_crisis_tight,
        'improvement': delta,
        'avg_multiplier': mean_crisis_mult
    },
    'crisis_loose': {
        'description': 'Crisis regime + loose fundamentals (<40)',
        'expected_behavior': 'Amplify bearish positions',
        'baseline_sharpe': baseline_sharpe_crisis_loose,
        'test_sharpe': test_sharpe_crisis_loose,
        'improvement': delta,
        'avg_multiplier': mean_crisis_mult
    },
    'crisis_neutral': {
        'description': 'Crisis regime + neutral fundamentals (40-70)',
        'expected_behavior': 'Mixed/reduce slightly',
        'baseline_sharpe': baseline_sharpe_crisis_neutral,
        'test_sharpe': test_sharpe_crisis_neutral,
        'improvement': delta,
        'avg_multiplier': mean_crisis_mult
    }
}
```

#### Historical Event Validation

```python
# Test specific historical crises
historical_crises = [
    {
        'period': '2008-09-01 to 2009-03-31',
        'event': 'GFC / Lehman collapse',
        'crisis_regime': 'CRISIS',
        'tightness': 12,  # Extreme loose (demand destruction)
        'expected_behavior': 'Amplify bearish',
        'expected_multiplier': 1.3,
        'base_position': -0.9,
        'expected_final_position': -1.17
    },
    {
        'period': '2010-05-01 to 2010-12-31',
        'event': 'European debt crisis + mine disruptions',
        'crisis_regime': 'PRE_CRISIS to CRISIS',
        'tightness': 78,  # Tight (near extreme)
        'expected_behavior': 'Amplify bullish',
        'expected_multiplier': 1.3,
        'base_position': 0.7,
        'expected_final_position': 0.91
    },
    {
        'period': '2011-08-01 to 2011-12-31',
        'event': 'US debt ceiling crisis',
        'crisis_regime': 'STRESS to PRE_CRISIS',
        'tightness': 52,  # Neutral
        'expected_behavior': 'Mixed behavior',
        'expected_multiplier': 0.8-1.0,
        'base_position': 0.3,
        'expected_final_position': 0.24-0.30
    },
    {
        'period': '2020-03-01 to 2020-03-31',
        'event': 'COVID crash',
        'crisis_regime': 'CRISIS',
        'tightness': 25,  # Loose (demand shock)
        'expected_behavior': 'Amplify bearish initially',
        'expected_multiplier': 1.3,
        'base_position': -0.6,
        'expected_final_position': -0.78
    }
]

# Validate each crisis
for crisis in historical_crises:
    # Get actual data for period
    period_data = get_period_data(crisis['period'])
    
    # Check crisis regime detected correctly
    actual_crisis_regime = period_data['crisis_regime'].mode()[0]
    assert actual_crisis_regime in crisis['crisis_regime'], \
        f"Crisis regime not detected for {crisis['event']}"
    
    # Check tightness score
    actual_tightness = period_data['tightness_score'].mean()
    assert abs(actual_tightness - crisis['tightness']) < 10, \
        f"Tightness score mismatch for {crisis['event']}"
    
    # Check amplification applied correctly
    actual_multiplier = period_data['crisis_mult'].mean()
    if isinstance(crisis['expected_multiplier'], tuple):
        assert crisis['expected_multiplier'][0] <= actual_multiplier <= crisis['expected_multiplier'][1], \
            f"Multiplier out of range for {crisis['event']}"
    else:
        assert abs(actual_multiplier - crisis['expected_multiplier']) < 0.2, \
            f"Multiplier incorrect for {crisis['event']}"
```

#### Anti-Goal Tests (CRITICAL!)

```python
# Verify CrisisCore v2 does NOT repeat old mistakes

anti_goal_tests = {
    'no_defensive_cuts': {
        'test': 'Verify CrisisCore does not cut positions during profitable crises',
        'method': 'Check that crisis multiplier is NOT <1.0 when trend profitable',
        'historical_example': '2008 GFC',
        'old_behavior': 'Cut to 0.25Ã— sizing',
        'new_behavior': 'Amplify bearish 1.3Ã— (if loose) or neutral (if neutral)',
        'validation': lambda: assert_no_defensive_cuts_in_profitable_crises()
    },
    'no_chop_overlap': {
        'test': 'Verify CrisisCore does not fire when ChopCore active',
        'method': 'Check crisis_mult == 1.0 whenever chop_regime != NORMAL',
        'validation': lambda: assert_crisis_blocked_during_chop()
    },
    'no_extreme_overlap': {
        'test': 'Verify CrisisCore does not fire when tightness extreme',
        'method': 'Check crisis_mult == 1.0 when tightness >80 or <20',
        'validation': lambda: assert_crisis_blocked_during_extreme()
    }
}

# Run anti-goal tests
for test_name, test_config in anti_goal_tests.items():
    result = test_config['validation']()
    assert result == True, f"Anti-goal test failed: {test_name}"
```

#### Output Report

```markdown
# CrisisCore v2 Directional Standalone Test Results

## Crisis Regime Frequency
- CRISIS: 4.2% of time
- PRE_CRISIS: 6.8% of time
- STRESS: 12.5% of time
- NORMAL: 76.5% of time
- âœ… Frequencies within expected ranges

## Performance by Scenario
| Scenario       | Baseline Sharpe | Test Sharpe | Improvement | Avg Multiplier |
|----------------|-----------------|-------------|-------------|----------------|
| Crisis + Tight | +0.92           | +1.08       | **+0.16**   | 1.28Ã—          |
| Crisis + Loose | +0.65           | +0.78       | **+0.13**   | 1.31Ã—          |
| Crisis + Neutral | +0.48         | +0.51       | **+0.03**   | 0.85Ã—          |

## Historical Event Validation
âœ… 2008 GFC: CRISIS + loose, amplified bearish 1.3Ã—
âœ… 2010 Europe: PRE_CRISIS + tight, amplified bullish 1.3Ã—
âœ… 2011 Debt Ceiling: STRESS + neutral, mixed 0.8-1.0Ã—
âœ… 2020 COVID: CRISIS + loose, amplified bearish 1.3Ã—

## Anti-Goal Tests (Critical!)
âœ… No defensive cuts during profitable crises
âœ… CrisisCore blocked when ChopCore active
âœ… CrisisCore blocked when tightness extreme

## Conclusion
CrisisCore v2 Directional works as intended:
- Provides directional amplification based on crisis + tightness âœ…
- Amplifies correctly: tightâ†’bullish, looseâ†’bearish âœ…
- Neutral behavior when fundamentals mixed âœ…
- Does NOT repeat old mistakes (defensive cutting) âœ…

**PASS: Proceed to Phase 2 (Combined System Testing)**
```

---

## PHASE 2: COMBINED SYSTEM VALIDATION

**Objective:** Validate that overlays interact correctly via priority hierarchy, without conflicts or unintended behavior

**Duration:** Week 2

**Philosophy:** After proving components work individually, test integration logic

### Test 2A: Priority Hierarchy Logic

#### Purpose
Confirm that the three overlays interact correctly according to the priority system, with no conflicts or race conditions.

#### Test Cases

```python
# Define comprehensive test scenarios
priority_test_cases = [
    {
        'name': 'Priority 1 Override: Extreme Tight Overrides Chop',
        'inputs': {
            'base_position': 0.8,
            'chop_regime': 'HIGH_CHOP',
            'crisis_regime': 'NORMAL',
            'tightness_score': 95
        },
        'expected': {
            'priority': 'EXTREME_TIGHT_OVERRIDE',
            'chop_mult': 0.75,  # Light reduction (not full 0.5Ã—)
            'crisis_mult': 1.5,  # Amplification
            'final_position': 0.9,  # 0.8 Ã— 0.75 Ã— 1.5
            'scenario': 'EXTREME_TIGHT_OVERRIDE',
            'notes': 'Grasberg meteorite type event'
        }
    },
    {
        'name': 'Priority 1 Override: Extreme Loose Overrides Crisis',
        'inputs': {
            'base_position': -0.9,
            'chop_regime': 'MILD_CHOP',
            'crisis_regime': 'CRISIS',
            'tightness_score': 12
        },
        'expected': {
            'priority': 'EXTREME_LOOSE_OVERRIDE',
            'chop_mult': 0.9,  # Light reduction
            'crisis_mult': 1.5,  # Amplify bearish
            'final_position': -1.215,  # -0.9 Ã— 0.9 Ã— 1.5
            'scenario': 'EXTREME_LOOSE_OVERRIDE',
            'notes': '2008 GFC type demand destruction'
        }
    },
    {
        'name': 'Priority 2 Override: Chop Blocks Crisis Directional',
        'inputs': {
            'base_position': 0.5,
            'chop_regime': 'HIGH_CHOP',
            'crisis_regime': 'STRESS',
            'tightness_score': 48  # Normal, not extreme
        },
        'expected': {
            'priority': 'CHOP_OVERRIDE',
            'chop_mult': 0.5,
            'crisis_mult': 1.0,  # BLOCKED!
            'final_position': 0.25,  # 0.5 Ã— 0.5
            'scenario': 'CHOP_OVERRIDE_HIGH_CHOP',
            'notes': '2018 trade war type confusion'
        }
    },
    {
        'name': 'Priority 2 Override: Mild Chop Blocks Crisis',
        'inputs': {
            'base_position': 0.6,
            'chop_regime': 'MILD_CHOP',
            'crisis_regime': 'PRE_CRISIS',
            'tightness_score': 55  # Normal
        },
        'expected': {
            'priority': 'CHOP_OVERRIDE',
            'chop_mult': 0.75,
            'crisis_mult': 1.0,  # BLOCKED!
            'final_position': 0.45,  # 0.6 Ã— 0.75
            'scenario': 'CHOP_OVERRIDE_MILD_CHOP',
            'notes': 'Moderate macro confusion'
        }
    },
    {
        'name': 'Priority 3: Crisis + Tight Directional (No Chop)',
        'inputs': {
            'base_position': 1.0,
            'chop_regime': 'NORMAL',
            'crisis_regime': 'PRE_CRISIS',
            'tightness_score': 72  # Tight but not extreme
        },
        'expected': {
            'priority': 'CRISIS_TIGHTNESS_DIRECTIONAL',
            'chop_mult': 1.0,
            'crisis_mult': 1.3,  # Amplify bullish
            'final_position': 1.3,  # 1.0 Ã— 1.3
            'scenario': 'CRISIS_TIGHTNESS_DIRECTIONAL',
            'notes': 'Crisis + tight â†’ amplify bullish'
        }
    },
    {
        'name': 'Priority 3: Crisis + Loose Directional (No Chop)',
        'inputs': {
            'base_position': -0.8,
            'chop_regime': 'NORMAL',
            'crisis_regime': 'CRISIS',
            'tightness_score': 28  # Loose but not extreme
        },
        'expected': {
            'priority': 'CRISIS_TIGHTNESS_DIRECTIONAL',
            'chop_mult': 1.0,
            'crisis_mult': 1.3,  # Amplify bearish
            'final_position': -1.04,  # -0.8 Ã— 1.3
            'scenario': 'CRISIS_TIGHTNESS_DIRECTIONAL',
            'notes': 'Crisis + loose â†’ amplify bearish'
        }
    },
    {
        'name': 'Normal Operations: No Overlays Fire',
        'inputs': {
            'base_position': 0.7,
            'chop_regime': 'NORMAL',
            'crisis_regime': 'NORMAL',
            'tightness_score': 50  # Neutral
        },
        'expected': {
            'priority': 'NORMAL',
            'chop_mult': 1.0,
            'crisis_mult': 1.0,
            'final_position': 0.7,  # 0.7 Ã— 1.0 Ã— 1.0
            'scenario': 'NORMAL',
            'notes': 'No overlay conditions met'
        }
    },
    {
        'name': 'Conflict Test: Extreme Tight + Bearish Position',
        'inputs': {
            'base_position': -0.6,
            'chop_regime': 'NORMAL',
            'crisis_regime': 'NORMAL',
            'tightness_score': 88  # Extreme tight
        },
        'expected': {
            'priority': 'EXTREME_TIGHT_CONFLICT',
            'chop_mult': 1.0,
            'crisis_mult': 0.5,  # DAMPEN conflicting bearish
            'final_position': -0.3,  # -0.6 Ã— 0.5
            'scenario': 'EXTREME_TIGHT_CONFLICT',
            'notes': 'Extreme tight conflicts with bearish position'
        }
    }
]
```

#### Validation Method

```python
def test_priority_hierarchy():
    """
    Test all priority hierarchy scenarios.
    """
    results = []
    
    for test_case in priority_test_cases:
        # Run overlay logic
        final_position, diagnostics = apply_crisis_directional_overlay(
            base_position=test_case['inputs']['base_position'],
            chop_regime=test_case['inputs']['chop_regime'],
            crisis_regime=test_case['inputs']['crisis_regime'],
            tightness_score=test_case['inputs']['tightness_score']
        )
        
        # Validate results
        errors = []
        
        if diagnostics['priority'] != test_case['expected']['priority']:
            errors.append(f"Priority mismatch: {diagnostics['priority']} != {test_case['expected']['priority']}")
        
        if abs(diagnostics['chop_mult'] - test_case['expected']['chop_mult']) > 0.01:
            errors.append(f"Chop mult mismatch: {diagnostics['chop_mult']} != {test_case['expected']['chop_mult']}")
        
        if abs(diagnostics['crisis_mult'] - test_case['expected']['crisis_mult']) > 0.01:
            errors.append(f"Crisis mult mismatch: {diagnostics['crisis_mult']} != {test_case['expected']['crisis_mult']}")
        
        if abs(final_position - test_case['expected']['final_position']) > 0.01:
            errors.append(f"Final position mismatch: {final_position} != {test_case['expected']['final_position']}")
        
        # Record result
        results.append({
            'test_name': test_case['name'],
            'passed': len(errors) == 0,
            'errors': errors,
            'diagnostics': diagnostics
        })
    
    return results
```

#### Output Report

```markdown
# Priority Hierarchy Test Results

## Test Summary
- Total tests: 8
- Passed: 8
- Failed: 0
- Pass rate: 100%

## Detailed Results

### âœ… Priority 1 Override: Extreme Tight Overrides Chop
- Inputs: base=0.8, chop=HIGH_CHOP, crisis=NORMAL, tight=95
- Expected: EXTREME_TIGHT_OVERRIDE, final=0.9
- Actual: EXTREME_TIGHT_OVERRIDE, final=0.90
- **PASS**

### âœ… Priority 1 Override: Extreme Loose Overrides Crisis
- Inputs: base=-0.9, chop=MILD_CHOP, crisis=CRISIS, tight=12
- Expected: EXTREME_LOOSE_OVERRIDE, final=-1.215
- Actual: EXTREME_LOOSE_OVERRIDE, final=-1.215
- **PASS**

### âœ… Priority 2 Override: Chop Blocks Crisis Directional
- Inputs: base=0.5, chop=HIGH_CHOP, crisis=STRESS, tight=48
- Expected: CHOP_OVERRIDE, crisis_mult=1.0 (blocked)
- Actual: CHOP_OVERRIDE, crisis_mult=1.0 (blocked)
- **PASS**

### âœ… Priority 2 Override: Mild Chop Blocks Crisis
- Inputs: base=0.6, chop=MILD_CHOP, crisis=PRE_CRISIS, tight=55
- Expected: CHOP_OVERRIDE, crisis_mult=1.0 (blocked)
- Actual: CHOP_OVERRIDE, crisis_mult=1.0 (blocked)
- **PASS**

### âœ… Priority 3: Crisis + Tight Directional (No Chop)
- Inputs: base=1.0, chop=NORMAL, crisis=PRE_CRISIS, tight=72
- Expected: CRISIS_TIGHTNESS_DIRECTIONAL, final=1.3
- Actual: CRISIS_TIGHTNESS_DIRECTIONAL, final=1.30
- **PASS**

### âœ… Priority 3: Crisis + Loose Directional (No Chop)
- Inputs: base=-0.8, chop=NORMAL, crisis=CRISIS, tight=28
- Expected: CRISIS_TIGHTNESS_DIRECTIONAL, final=-1.04
- Actual: CRISIS_TIGHTNESS_DIRECTIONAL, final=-1.04
- **PASS**

### âœ… Normal Operations: No Overlays Fire
- Inputs: base=0.7, chop=NORMAL, crisis=NORMAL, tight=50
- Expected: NORMAL, final=0.7
- Actual: NORMAL, final=0.70
- **PASS**

### âœ… Conflict Test: Extreme Tight + Bearish Position
- Inputs: base=-0.6, chop=NORMAL, crisis=NORMAL, tight=88
- Expected: EXTREME_TIGHT_CONFLICT, final=-0.3 (dampened)
- Actual: EXTREME_TIGHT_CONFLICT, final=-0.30
- **PASS**

## Conclusion
Priority hierarchy logic works correctly:
- Extreme fundamentals override chop and crisis âœ…
- ChopCore blocks CrisisCore directional âœ…
- CrisisCore only fires when chop=NORMAL âœ…
- Conflict handling works (dampen opposing positions) âœ…
- Normal operations unaffected âœ…

**PASS: Proceed to Test 2B**
```

---

### Test 2B: Historical Forensic Analysis

#### Purpose
Validate system behavior during 15-20 major historical market events to ensure overlays trigger correctly in real-world scenarios.

#### Historical Events Catalog

```python
# Comprehensive historical events spanning 2000-2025
historical_events = [
    # EXTREME TIGHT EVENTS
    {
        'period': '2006-06-01 to 2006-09-30',
        'event': 'Grasberg Mine Strike (Freeport)',
        'expected_overlay': 'EXTREME_TIGHT_OVERRIDE',
        'expected_tightness': 85,
        'expected_chop': 'MILD_CHOP',
        'expected_priority': 'EXTREME overrides chop',
        'expected_amplification': 1.5,
        'base_direction': 'bullish',
        'notes': 'Major copper supply disruption, ~450kt affected'
    },
    {
        'period': '2010-11-01 to 2011-02-28',
        'event': 'Codelco Mine Closures + Chile Earthquake',
        'expected_overlay': 'EXTREME_TIGHT_OVERRIDE',
        'expected_tightness': 82,
        'expected_chop': 'NORMAL',
        'expected_priority': 'Extreme tight, no chop',
        'expected_amplification': 1.5,
        'base_direction': 'bullish',
        'notes': 'Multiple supply disruptions, physical squeeze'
    },
    {
        'period': '2021-05-01 to 2021-08-31',
        'event': 'Chile Copper Supply Squeeze',
        'expected_overlay': 'EXTREME_TIGHT_OVERRIDE',
        'expected_tightness': 87,
        'expected_chop': 'NORMAL',
        'expected_priority': 'Extreme tight, no chop',
        'expected_amplification': 1.5,
        'base_direction': 'bullish',
        'notes': 'Water restrictions, labor issues, inventory crash'
    },
    
    # EXTREME LOOSE EVENTS
    {
        'period': '2008-09-01 to 2009-03-31',
        'event': 'GFC / Lehman Collapse',
        'expected_overlay': 'EXTREME_LOOSE_OVERRIDE',
        'expected_tightness': 12,
        'expected_chop': 'NORMAL to MILD_CHOP',
        'expected_priority': 'Extreme loose, strong bearish trend',
        'expected_amplification': 1.5,
        'base_direction': 'bearish',
        'notes': 'Demand destruction, prices -65%'
    },
    {
        'period': '2015-07-01 to 2015-12-31',
        'event': 'China Slowdown + Commodity Crash',
        'expected_overlay': 'EXTREME_LOOSE_OVERRIDE initially',
        'expected_tightness': 18,
        'expected_chop': 'HIGH_CHOP',
        'expected_priority': 'Extreme loose early, then chop takes over',
        'expected_amplification': 'Mixed (extreme early, chop later)',
        'base_direction': 'bearish then rangebound',
        'notes': 'China growth concerns, inventory buildup'
    },
    
    # HIGH CHOP EVENTS (Normal Fundamentals)
    {
        'period': '2018-03-01 to 2018-11-30',
        'event': 'Trade War Range / Macro Confusion',
        'expected_overlay': 'CHOP_OVERRIDE',
        'expected_tightness': 48,
        'expected_chop': 'HIGH_CHOP',
        'expected_priority': 'Chop blocks crisis signals',
        'expected_sizing': 0.5,
        'base_direction': 'rangebound',
        'notes': 'Trump tariffs, tit-for-tat, macro uncertainty'
    },
    {
        'period': '2015-03-01 to 2016-01-31',
        'event': 'China Slowdown Range',
        'expected_overlay': 'CHOP_OVERRIDE to EXTREME_LOOSE',
        'expected_tightness': '25-45 (transitioning)',
        'expected_chop': 'HIGH_CHOP',
        'expected_priority': 'Chop dominates until extreme loose',
        'expected_sizing': 0.5,
        'base_direction': 'rangebound then bearish',
        'notes': 'Extended range, macro cross-currents'
    },
    {
        'period': '2011-08-01 to 2011-12-31',
        'event': 'US Debt Ceiling + Europe Debt Crisis',
        'expected_overlay': 'CHOP_OVERRIDE or MILD_CHOP',
        'expected_tightness': 52,
        'expected_chop': 'MILD_CHOP to HIGH_CHOP',
        'expected_priority': 'Chop from conflicting narratives',
        'expected_sizing': 0.75,
        'base_direction': 'rangebound',
        'notes': 'Political drama, fear vs stabilization'
    },
    
    # CRISIS + TIGHTNESS DIRECTIONAL (No Chop)
    {
        'period': '2010-05-01 to 2010-09-30',
        'event': 'Flash Crash + European Debt + Supply Issues',
        'expected_overlay': 'CRISIS_TIGHTNESS_DIRECTIONAL',
        'expected_tightness': 75,
        'expected_chop': 'NORMAL',
        'expected_priority': 'Crisis + tight â†’ amplify bullish',
        'expected_amplification': 1.3,
        'base_direction': 'bullish',
        'notes': 'Crisis but tight fundamentals support prices'
    },
    {
        'period': '2016-01-01 to 2016-02-29',
        'event': 'China Market Crash + Oil Collapse',
        'expected_overlay': 'CRISIS_TIGHTNESS_DIRECTIONAL',
        'expected_tightness': 35,
        'expected_chop': 'NORMAL to MILD_CHOP',
        'expected_priority': 'Crisis + loose â†’ amplify bearish',
        'expected_amplification': 1.3,
        'base_direction': 'bearish',
        'notes': 'Broad commodity selloff, copper follows'
    },
    {
        'period': '2020-03-01 to 2020-03-31',
        'event': 'COVID Crash (March 2020)',
        'expected_overlay': 'CRISIS_TIGHTNESS_DIRECTIONAL initially',
        'expected_tightness': 25,
        'expected_chop': 'NORMAL (strong trend)',
        'expected_priority': 'Crisis + loose â†’ amplify bearish',
        'expected_amplification': 1.3,
        'base_direction': 'bearish',
        'notes': 'Sharp selloff, demand fears, no chop during crash'
    },
    
    # NORMAL PERIODS (No Overlay)
    {
        'period': '2017-01-01 to 2017-12-31',
        'event': 'Synchronized Global Growth',
        'expected_overlay': 'NORMAL',
        'expected_tightness': 55,
        'expected_chop': 'NORMAL',
        'expected_priority': 'No overlays needed',
        'expected_multipliers': 1.0,
        'base_direction': 'bullish trend',
        'notes': 'Clean trend, no crises, no confusion'
    },
    {
        'period': '2019-01-01 to 2019-12-31',
        'event': 'Trade Truce + Steady Growth',
        'expected_overlay': 'NORMAL to MILD_CHOP',
        'expected_tightness': 50,
        'expected_chop': 'NORMAL to MILD_CHOP',
        'expected_priority': 'Mostly normal operations',
        'expected_multipliers': 1.0,
        'base_direction': 'rangebound with upward bias',
        'notes': 'Stable environment, occasional noise'
    },
    
    # MIXED/TRANSITION PERIODS
    {
        'period': '2022-01-01 to 2022-12-31',
        'event': 'Ukraine War + China COVID Zero',
        'expected_overlay': 'MIXED (Crisis + Chop)',
        'expected_tightness': '40-65 (volatile)',
        'expected_chop': 'HIGH_CHOP',
        'expected_priority': 'Chop dominates conflicting narratives',
        'expected_sizing': 0.5,
        'base_direction': 'rangebound',
        'notes': 'War premium vs China demand destruction'
    },
    {
        'period': '2023-01-01 to 2024-06-30',
        'event': 'China Reopening + Banking Crisis',
        'expected_overlay': 'MIXED (transition)',
        'expected_tightness': '45-58',
        'expected_chop': 'MILD_CHOP to NORMAL',
        'expected_priority': 'Transitional, some chop',
        'expected_sizing': '0.75-1.0',
        'base_direction': 'rangebound to bullish',
        'notes': 'Multiple regime transitions'
    }
]
```

#### Validation Methodology

```python
def validate_historical_events():
    """
    Forensic analysis of historical events.
    """
    results = []
    
    for event in historical_events:
        # Load actual backtest data for period
        period_data = load_backtest_data(
            start_date=event['period'].split(' to ')[0],
            end_date=event['period'].split(' to ')[1]
        )
        
        # Extract actual overlay behavior
        actual_overlay = period_data['final_regime'].mode()[0]
        actual_tightness = period_data['tightness_score'].mean()
        actual_chop = period_data['chop_regime'].mode()[0]
        actual_priority = period_data['priority'].mode()[0]
        
        # Calculate metrics
        expected_triggers = event['expected_overlay']
        actual_triggers = actual_overlay
        
        # Validate
        match = True
        errors = []
        
        # Check overlay triggered correctly
        if 'MIXED' not in expected_triggers:
            if expected_triggers not in actual_triggers:
                match = False
                errors.append(f"Overlay mismatch: expected {expected_triggers}, got {actual_triggers}")
        
        # Check tightness score
        if isinstance(event['expected_tightness'], int):
            if abs(actual_tightness - event['expected_tightness']) > 15:
                match = False
                errors.append(f"Tightness mismatch: expected {event['expected_tightness']}, got {actual_tightness:.0f}")
        
        # Check chop regime (if specific)
        if 'to' not in event['expected_chop']:
            if event['expected_chop'] not in actual_chop:
                match = False
                errors.append(f"Chop mismatch: expected {event['expected_chop']}, got {actual_chop}")
        
        # Record result
        results.append({
            'event': event['event'],
            'period': event['period'],
            'match': match,
            'errors': errors,
            'expected_overlay': expected_triggers,
            'actual_overlay': actual_triggers,
            'expected_tightness': event['expected_tightness'],
            'actual_tightness': actual_tightness,
            'notes': event['notes']
        })
    
    return results
```

#### Output Report

```markdown
# Historical Forensic Analysis Results

## Summary
- Total events analyzed: 15
- Correctly detected: 14
- Mismatches: 1
- Accuracy: 93.3%

## Extreme Tight Events (3/3 correct)
âœ… 2006 Grasberg Strike: EXTREME_TIGHT_OVERRIDE (tight=85)
âœ… 2010 Codelco Closures: EXTREME_TIGHT_OVERRIDE (tight=82)
âœ… 2021 Chile Squeeze: EXTREME_TIGHT_OVERRIDE (tight=87)

## Extreme Loose Events (2/2 correct)
âœ… 2008 GFC: EXTREME_LOOSE_OVERRIDE (tight=12)
âœ… 2015 China Slowdown: EXTREME_LOOSE â†’ CHOP transition (tight=18â†’28)

## High Chop Events (3/3 correct)
âœ… 2018 Trade War: CHOP_OVERRIDE (chop=HIGH_CHOP, tight=48)
âœ… 2015-2016 Range: CHOP_OVERRIDE (chop=HIGH_CHOP, tight=38)
âœ… 2011 Debt Ceiling: CHOP_OVERRIDE (chop=MILD_CHOP, tight=52)

## Crisis + Tightness Directional (3/3 correct)
âœ… 2010 Flash Crash: CRISIS_TIGHT amplify bullish (tight=75, crisis=PRE_CRISIS)
âœ… 2016 China Crash: CRISIS_LOOSE amplify bearish (tight=35, crisis=CRISIS)
âœ… 2020 COVID March: CRISIS_LOOSE amplify bearish (tight=25, crisis=CRISIS)

## Normal Periods (2/2 correct)
âœ… 2017 Global Growth: NORMAL operations (tight=55, chop=NORMAL)
âœ… 2019 Trade Truce: NORMAL to MILD_CHOP (tight=50, chop=NORMAL)

## Mixed/Transition Periods (1/2 correct)
âœ… 2022 Ukraine War: CHOP_OVERRIDE dominates (chop=HIGH_CHOP)
âš ï¸ 2023-2024 Reopening: Expected MILD_CHOP, got NORMAL more than expected
   - Not a failure - regime boundaries are fuzzy for transition periods
   - System behavior still appropriate (no overlay errors)

## Conclusion
Forensic validation passed:
- All major supply shocks detected correctly (extreme tight) âœ…
- All major demand collapses detected correctly (extreme loose) âœ…
- All major range-bound periods detected correctly (chop) âœ…
- Crisis directional logic worked correctly âœ…
- One fuzzy boundary case (transition period) - acceptable âœ…

**PASS: Proceed to Phase 3 (Robustness Testing)**
```

---

## PHASE 3: ROBUSTNESS TESTING

**Objective:** Stress test overlays against overfitting, parameter sensitivity, and out-of-sample degradation

**Duration:** Week 3

**Philosophy:** Renaissance principle - strategies must be robust to parameter changes and work out-of-sample

### Test 3A: Parameter Sensitivity Analysis

#### Purpose
Ensure overlay thresholds aren't overfit to specific values and system degrades gracefully when parameters vary.

#### Parameters to Test

```python
sensitivity_parameters = {
    'extreme_tight_threshold': {
        'baseline': 80,
        'test_range': [75, 77, 80, 82, 85],
        'expected_behavior': 'Gradual transition, no cliff effects'
    },
    'extreme_loose_threshold': {
        'baseline': 20,
        'test_range': [15, 18, 20, 22, 25],
        'expected_behavior': 'Gradual transition, no cliff effects'
    },
    'tight_threshold': {
        'baseline': 70,
        'test_range': [65, 67, 70, 73, 75],
        'expected_behavior': 'Gradual change in crisis amplification'
    },
    'loose_threshold': {
        'baseline': 40,
        'test_range': [35, 37, 40, 43, 45],
        'expected_behavior': 'Gradual change in crisis amplification'
    },
    'high_chop_threshold': {
        'baseline': 0.55,
        'test_range': [0.50, 0.53, 0.55, 0.58, 0.60],
        'expected_behavior': 'Smooth degradation'
    },
    'mild_chop_threshold': {
        'baseline': 0.35,
        'test_range': [0.30, 0.33, 0.35, 0.38, 0.40],
        'expected_behavior': 'Smooth degradation'
    },
    'chop_mult_high': {
        'baseline': 0.50,
        'test_range': [0.40, 0.45, 0.50, 0.55, 0.60],
        'expected_behavior': 'Linear relationship to Sharpe'
    },
    'crisis_amplification': {
        'baseline': 1.3,
        'test_range': [1.1, 1.2, 1.3, 1.4, 1.5],
        'expected_behavior': 'Monotonic improvement'
    }
}
```

#### Testing Method

```python
def run_sensitivity_analysis(parameter_name, test_range, baseline_value):
    """
    Vary one parameter while holding others constant.
    """
    results = []
    
    # Get baseline performance
    baseline_sharpe = run_backtest_with_defaults()['sharpe']
    
    # Test each value in range
    for value in test_range:
        # Create config with varied parameter
        config = get_default_config()
        config[parameter_name] = value
        
        # Run backtest
        backtest_result = run_backtest(config)
        
        # Record metrics
        results.append({
            'parameter': parameter_name,
            'value': value,
            'sharpe': backtest_result['sharpe'],
            'sharpe_delta': backtest_result['sharpe'] - baseline_sharpe,
            'max_drawdown': backtest_result['max_drawdown'],
            'trigger_frequency': backtest_result['trigger_frequency']
        })
    
    return results
```

#### Robustness Criteria

```python
# Define acceptance criteria
robustness_tests = {
    'gradual_degradation': {
        'test': 'Sharpe should degrade gradually, not cliff',
        'method': lambda results: check_max_adjacent_delta(results) < 0.05,
        'threshold': 0.05,
        'description': 'Adjacent parameter values should not differ by >0.05 Sharpe'
    },
    'stable_around_baseline': {
        'test': 'Sharpe within Â±0.05 for Â±5% parameter change',
        'method': lambda results: check_baseline_stability(results, baseline_idx=2, tolerance=0.05),
        'threshold': 0.05,
        'description': 'Small parameter changes should not drastically change performance'
    },
    'no_extreme_sensitivity': {
        'test': 'No single parameter dominates performance',
        'method': lambda results: max(results['sharpe']) - min(results['sharpe']) < 0.15,
        'threshold': 0.15,
        'description': 'Full parameter range should not vary >0.15 Sharpe'
    }
}
```

#### Output Report Template

```markdown
# Parameter Sensitivity Analysis: [PARAMETER_NAME]

## Test Configuration
- Parameter: [parameter_name]
- Baseline Value: [baseline]
- Test Range: [min] to [max]
- Number of Tests: [n]

## Results
| Value | Sharpe | Delta vs Baseline | Max DD | Trigger Freq |
|-------|--------|-------------------|--------|--------------|
| 75    | 0.812  | +0.045           | -22.3% | 1.8%         |
| 77    | 0.805  | +0.038           | -22.5% | 1.6%         |
| 80    | 0.767  | 0.000 (baseline) | -23.1% | 1.4%         |
| 82    | 0.743  | -0.024           | -23.8% | 1.2%         |
| 85    | 0.721  | -0.046           | -24.5% | 0.9%         |

## Visualization
[Chart showing Sharpe vs Parameter Value - should be smooth curve, not jagged]

## Robustness Checks
âœ… Gradual degradation: Max adjacent delta = 0.024 < 0.05 threshold
âœ… Stable around baseline: Â±5% parameter change â†’ Â±0.038 Sharpe (within Â±0.05)
âœ… No extreme sensitivity: Full range = 0.091 Sharpe (< 0.15 threshold)

## Conclusion
Parameter [parameter_name] is ROBUST:
- Smooth transition across range âœ…
- No cliff effects âœ…
- Baseline value is near-optimal âœ…
- System not hypersensitive to exact threshold âœ…

**PASS**
```

---

### Test 3B: Walk-Forward Validation

#### Purpose
Prevent look-ahead bias and validate that overlays work out-of-sample by training on historical data and testing on future unseen data.

#### Walk-Forward Windows

```python
walk_forward_windows = [
    {
        'name': 'Window 1: Pre-GFC Training',
        'train': '2000-01-01 to 2010-12-31',
        'test': '2011-01-01 to 2015-12-31',
        'train_years': 11,
        'test_years': 5,
        'notes': 'Train through GFC, test European debt + China slowdown'
    },
    {
        'name': 'Window 2: Pre-China Slowdown Training',
        'train': '2000-01-01 to 2015-12-31',
        'test': '2016-01-01 to 2020-12-31',
        'train_years': 16,
        'test_years': 5,
        'notes': 'Train through China slowdown, test Trump era + COVID'
    },
    {
        'name': 'Window 3: Pre-COVID Training',
        'train': '2000-01-01 to 2020-12-31',
        'test': '2021-01-01 to 2025-10-31',
        'train_years': 21,
        'test_years': 4.8,
        'notes': 'Train through COVID crash, test reopening + Ukraine'
    },
    {
        'name': 'Window 4: Expanding Window',
        'train': '2000-01-01 to 2017-12-31',
        'test': '2018-01-01 to 2022-12-31',
        'train_years': 18,
        'test_years': 5,
        'notes': 'Test recent trade war + COVID + reopening period'
    }
]
```

#### Walk-Forward Methodology

```python
def run_walk_forward_validation(window):
    """
    1. Calibrate overlay parameters on training data
    2. Freeze parameters
    3. Test on out-of-sample period
    4. Measure degradation
    """
    
    # Step 1: Optimize on training data
    train_data = load_data(window['train'])
    
    optimized_params = optimize_overlays(
        data=train_data,
        parameters_to_optimize=[
            'extreme_tight_threshold',
            'extreme_loose_threshold',
            'high_chop_threshold',
            'chop_mult_high',
            'crisis_amplification'
        ],
        optimization_metric='sharpe'
    )
    
    # Step 2: Record training performance
    train_results = run_backtest(train_data, optimized_params)
    train_sharpe = train_results['sharpe']
    
    # Step 3: Test on out-of-sample data (FROZEN parameters!)
    test_data = load_data(window['test'])
    test_results = run_backtest(test_data, optimized_params)  # Same params!
    test_sharpe = test_results['sharpe']
    
    # Step 4: Calculate degradation
    degradation_abs = train_sharpe - test_sharpe
    degradation_pct = (degradation_abs / train_sharpe) * 100
    
    return {
        'window': window['name'],
        'train_sharpe': train_sharpe,
        'test_sharpe': test_sharpe,
        'degradation_abs': degradation_abs,
        'degradation_pct': degradation_pct,
        'optimized_params': optimized_params
    }
```

#### Acceptance Criteria

```python
# Walk-forward passes if:
acceptance_criteria = {
    'degradation_limit': {
        'threshold': 0.20,  # <20% degradation acceptable
        'test': lambda result: result['degradation_pct'] < 20,
        'description': 'Out-of-sample Sharpe should not drop >20%'
    },
    'test_sharpe_positive': {
        'threshold': 0.0,
        'test': lambda result: result['test_sharpe'] > 0.0,
        'description': 'Must maintain positive Sharpe out-of-sample'
    },
    'consistent_across_windows': {
        'threshold': 0.30,
        'test': lambda results: (max([r['degradation_pct'] for r in results]) - 
                                 min([r['degradation_pct'] for r in results])) < 30,
        'description': 'Degradation should be consistent across windows'
    }
}
```

#### Output Report

```markdown
# Walk-Forward Validation Results

## Window 1: Pre-GFC Training (2000-2010 â†’ 2011-2015)
- Train Sharpe: 0.823
- Test Sharpe: 0.687
- Degradation: -0.136 (-16.5%)
- Status: âœ… PASS (<20% threshold)
- Notes: European debt crisis period, reasonable degradation

## Window 2: Pre-China Slowdown (2000-2015 â†’ 2016-2020)
- Train Sharpe: 0.798
- Test Sharpe: 0.712
- Degradation: -0.086 (-10.8%)
- Status: âœ… PASS (<20% threshold)
- Notes: Trump era + COVID, strong out-of-sample performance

## Window 3: Pre-COVID Training (2000-2020 â†’ 2021-2025)
- Train Sharpe: 0.785
- Test Sharpe: 0.625
- Degradation: -0.160 (-20.4%)
- Status: âš ï¸ BORDERLINE (just above 20% threshold)
- Notes: Ukraine war + China reopening challenges, acceptable

## Window 4: Expanding Window (2000-2017 â†’ 2018-2022)
- Train Sharpe: 0.811
- Test Sharpe: 0.698
- Degradation: -0.113 (-13.9%)
- Status: âœ… PASS (<20% threshold)
- Notes: Recent period test, good performance

## Summary Statistics
- Average Degradation: 15.4%
- Degradation Range: 10.8% to 20.4%
- All Test Sharpes Positive: âœ… Yes
- Consistent Degradation: âœ… Yes (range <30%)

## Optimized Parameters (Stability Check)
| Parameter | Window 1 | Window 2 | Window 3 | Window 4 | Std Dev |
|-----------|----------|----------|----------|----------|---------|
| extreme_tight | 78 | 81 | 82 | 79 | 1.7 |
| extreme_loose | 22 | 19 | 18 | 21 | 1.7 |
| high_chop | 0.57 | 0.54 | 0.56 | 0.55 | 0.01 |
| chop_mult | 0.52 | 0.48 | 0.51 | 0.50 | 0.02 |
| crisis_amp | 1.28 | 1.32 | 1.31 | 1.29 | 0.02 |

âœ… Parameters stable across windows (low std dev)

## Conclusion
Walk-forward validation PASSED:
- Average degradation 15.4% (target: <20%) âœ…
- All out-of-sample periods maintained positive Sharpe âœ…
- Degradation consistent across windows âœ…
- Optimized parameters stable (not overfit to specific periods) âœ…

One window slightly above threshold (20.4%), but:
- Recent challenging period (Ukraine + China zero-COVID)
- Still positive Sharpe (0.625)
- Acceptable for real-world deployment

**PASS: Proceed to Test 3C**
```

---

### Test 3C: Regime Coverage Analysis

#### Purpose
Ensure overlays don't miss important regimes and that regime definitions cover the full opportunity set.

#### Analysis Method

```python
def analyze_regime_coverage():
    """
    Calculate regime frequencies and coverage.
    """
    
    # Load full backtest data
    data = load_full_backtest_data('2000-01-01', '2025-10-31')
    total_days = len(data)
    
    # Calculate frequencies
    regime_stats = {
        'EXTREME_TIGHT': {
            'days': len(data[data['tightness_score'] > 80]),
            'frequency': len(data[data['tightness_score'] > 80]) / total_days,
            'expected_freq': 0.014,  # 1.4%
            'coverage': 'Supply shocks'
        },
        'EXTREME_LOOSE': {
            'days': len(data[data['tightness_score'] < 20]),
            'frequency': len(data[data['tightness_score'] < 20]) / total_days,
            'expected_freq': 0.010,  # 1.0%
            'coverage': 'Demand collapses'
        },
        'HIGH_CHOP': {
            'days': len(data[data['chop_regime'] == 'HIGH_CHOP']),
            'frequency': len(data[data['chop_regime'] == 'HIGH_CHOP']) / total_days,
            'expected_freq': 0.06,  # 6%
            'coverage': 'Macro confusion'
        },
        'MILD_CHOP': {
            'days': len(data[data['chop_regime'] == 'MILD_CHOP']),
            'frequency': len(data[data['chop_regime'] == 'MILD_CHOP']) / total_days,
            'expected_freq': 0.08,  # 8%
            'coverage': 'Moderate confusion'
        },
        'CRISIS_TIGHT': {
            'days': len(data[(data['crisis_regime'].isin(['CRISIS', 'PRE_CRISIS'])) & 
                            (data['tightness_score'] > 70) & 
                            (data['chop_regime'] == 'NORMAL')]),
            'frequency': len(data[(data['crisis_regime'].isin(['CRISIS', 'PRE_CRISIS'])) & 
                                 (data['tightness_score'] > 70) & 
                                 (data['chop_regime'] == 'NORMAL')]) / total_days,
            'expected_freq': 0.03,  # 3%
            'coverage': 'Crisis + tight fundamentals'
        },
        'CRISIS_LOOSE': {
            'days': len(data[(data['crisis_regime'].isin(['CRISIS', 'PRE_CRISIS'])) & 
                            (data['tightness_score'] < 40) & 
                            (data['chop_regime'] == 'NORMAL')]),
            'frequency': len(data[(data['crisis_regime'].isin(['CRISIS', 'PRE_CRISIS'])) & 
                                 (data['tightness_score'] < 40) & 
                                 (data['chop_regime'] == 'NORMAL')]) / total_days,
            'expected_freq': 0.02,  # 2%
            'coverage': 'Crisis + loose fundamentals'
        },
        'NORMAL': {
            'days': len(data[(data['final_regime'] == 'NORMAL')]),
            'frequency': len(data[(data['final_regime'] == 'NORMAL')]) / total_days,
            'expected_freq': 0.70,  # 70%
            'coverage': 'Base strategy operations'
        }
    }
    
    return regime_stats
```

#### Dead Zone Analysis

```python
def identify_dead_zones():
    """
    Find periods where:
    1. Base system struggles (negative Sharpe)
    2. No overlay fires
    3. Suggests missing overlay or threshold issue
    """
    
    data = load_full_backtest_data('2000-01-01', '2025-10-31')
    
    # Find struggling periods with no overlay
    dead_zones = []
    
    for period in data.groupby(pd.Grouper(freq='Q')):  # Quarterly analysis
        quarter_data = period[1]
        
        # Calculate quarterly Sharpe
        quarter_sharpe = calculate_sharpe(quarter_data['base_returns'])
        
        # Check if struggling
        if quarter_sharpe < -0.50:
            # Check if overlays active
            overlay_active = (
                (quarter_data['final_regime'] != 'NORMAL').sum() / len(quarter_data)
            )
            
            # If struggling but no overlay, flag as dead zone
            if overlay_active < 0.10:  # <10% overlay activation
                dead_zones.append({
                    'period': period[0],
                    'sharpe': quarter_sharpe,
                    'overlay_activation': overlay_active,
                    'reason': 'Base system struggles, no overlay active'
                })
    
    return dead_zones
```

#### Output Report

```markdown
# Regime Coverage Analysis

## Regime Frequency Distribution
| Regime | Days | Frequency | Expected | Variance | Coverage |
|--------|------|-----------|----------|----------|----------|
| EXTREME_TIGHT | 87 | 1.4% | 1.4% | 0.0% | âœ… Supply shocks |
| EXTREME_LOOSE | 64 | 1.0% | 1.0% | 0.0% | âœ… Demand collapses |
| HIGH_CHOP | 387 | 6.2% | 6.0% | +0.2% | âœ… Macro confusion |
| MILD_CHOP | 521 | 8.3% | 8.0% | +0.3% | âœ… Moderate confusion |
| CRISIS_TIGHT | 182 | 2.9% | 3.0% | -0.1% | âœ… Crisis + tight |
| CRISIS_LOOSE | 135 | 2.2% | 2.0% | +0.2% | âœ… Crisis + loose |
| NORMAL | 4,324 | 69.2% | 70.0% | -0.8% | âœ… Base operations |

**Total: 6,250 days, ~25 years**

## Coverage Completeness
- Extreme events covered: âœ… Yes (2.4% of time)
- Chop periods covered: âœ… Yes (14.5% of time)
- Crisis directional covered: âœ… Yes (5.1% of time)
- Normal operations: âœ… Yes (69.2% of time)
- **Total coverage: 100%**

## Dead Zone Analysis
Periods where base system struggles (Sharpe <-0.50) but no overlay fires:

| Period | Sharpe | Overlay Active | Reason |
|--------|--------|----------------|--------|
| Q3 2014 | -0.62 | 4% | Mild confusion, below MILD_CHOP threshold |
| Q2 2022 | -0.58 | 8% | Ukraine uncertainty, just below HIGH_CHOP threshold |

**Total dead zones: 2 quarters (0.8% of time)**

## Dead Zone Remediation
1. Q3 2014: Chop score was 0.33 (just below 0.35 MILD_CHOP threshold)
   - Could lower threshold to 0.32, but risks over-triggering
   - Acceptable miss given low frequency

2. Q2 2022: Chop score was 0.52 (just below 0.55 HIGH_CHOP threshold)
   - Borderline case, Ukraine war created confusion but not full chop
   - Acceptable miss, would need 0.50 threshold (increases false positives)

## Conclusion
Regime coverage is COMPLETE:
- All major regime types represented âœ…
- Frequencies match expectations âœ…
- Dead zones minimal (0.8% of time) âœ…
- Dead zones are borderline threshold cases (acceptable) âœ…
- No major missing overlays or regime types âœ…

**PASS: Proceed to Phase 4 (Anti-Bias Safeguards)**
```

---

## PHASE 4: ANTI-BIAS SAFEGUARDS

**Objective:** Apply rigorous anti-overfitting tests including out-of-sample metals, random regime tests, and null hypothesis validation

**Duration:** Week 4

**Philosophy:** Renaissance principle - prove overlays add genuine value vs lucky data-mining

### Test 4A: Out-of-Sample Metal Test (Aluminum)

#### Purpose
Validate that overlay logic generalizes beyond copper to other base metals, proving concepts aren't copper-specific artifacts.

#### Aluminum Data Requirements

```python
aluminum_data_requirements = {
    'price': 'LME aluminum 3-month (daily, 2000-2025)',
    'inventory': 'LME aluminum total stocks (daily)',
    'canceled_stocks': 'LME aluminum cancelled warrants (daily)',
    'spreads': 'LME aluminum cash/3-month spread (daily)',
    'production': 'Global aluminum production estimates (quarterly)',
    'demand': 'Global aluminum demand estimates (quarterly)',
    'balance': 'Aluminum supply-demand balance (quarterly)',
    
    'macro_data': [
        'Same macro series as copper (DXY, CSI300, CNY, VIX, yields)',
        'Aluminum-specific positioning (CFTC if available)'
    ]
}
```

#### Tightness Index Adaptation

```python
def build_aluminum_tightness_index():
    """
    Adapt Tightness Index V5 for aluminum.
    
    Key differences:
    - Different days-of-consumption (aluminum consumes faster)
    - Different spread dynamics (more contango-prone)
    - Larger shadow stocks (9M tonnes off-exchange vs 1.3M visible)
    """
    
    config = {
        # Inventory component
        'inventory_lookback': 252,  # Same as copper
        'days_consumption_critical': 7,  # vs 10 for copper (faster consumption)
        'inventory_weight': 0.40,  # Slightly lower due to shadow stocks
        
        # Spread component
        'spread_lookback': 60,
        'backwardation_threshold': -10,  # Wider threshold (more contango)
        'spread_weight': 0.30,
        
        # Balance component
        'balance_weight': 0.30,  # Higher weight (more reliable for aluminum)
        
        # Disruption magnitude (same logic)
        'disruption_lookback': 20,
        'large_disruption_kt': 300,  # Lower than copper 400kt (different market size)
        'disruption_weight': 0.20
    }
    
    return config
```

#### Test Methodology

```python
def test_aluminum_overlays():
    """
    Apply SAME overlay logic to aluminum.
    """
    
    # Step 1: Build aluminum tightness index
    al_tightness = build_aluminum_tightness_index()
    
    # Step 2: Calculate aluminum ChopCore (SAME macro data!)
    al_chop = calculate_chopcore(
        dxy_data=shared_macro['dxy'],
        csi300_data=shared_macro['csi300'],
        china_yields=shared_macro['china_10y'],
        vix=shared_macro['vix'],
        cny_spread=shared_macro['cny_spread'],
        metal_adx=calculate_adx(al_price, 14)
    )
    
    # Step 3: Calculate aluminum CrisisCore (SAME HY spreads + VIX!)
    al_crisis = calculate_crisiscore(
        hy_spreads=shared_macro['hy_spread'],
        vix=shared_macro['vix']
    )
    
    # Step 4: Build aluminum base sleeves (adapt to aluminum)
    al_sleeves = build_aluminum_sleeves()
    
    # Step 5: Apply SAME overlay logic
    al_results = run_backtest_with_overlays(
        sleeves=al_sleeves,
        tightness=al_tightness,
        chop=al_chop,
        crisis=al_crisis,
        # SAME thresholds as copper!
        extreme_tight=80,
        extreme_loose=20,
        high_chop=0.55,
        crisis_amplification=1.3
    )
    
    return al_results
```

#### Acceptance Criteria

```python
aluminum_acceptance = {
    'overlays_trigger': {
        'test': 'Overlays must fire at reasonable frequency',
        'criteria': {
            'extreme_tight_freq': (0.01, 0.03),  # 1-3% of time
            'high_chop_freq': (0.05, 0.10),      # 5-10% of time
            'crisis_tight_freq': (0.02, 0.05)    # 2-5% of time
        }
    },
    'overlay_performance': {
        'test': 'Overlays must improve Sharpe on aluminum',
        'criteria': {
            'chopcore_improvement': 'Positive in chop regimes',
            'extreme_tight_improvement': 'Positive during supply shocks',
            'crisis_directional_logical': 'Correct directional behavior'
        }
    },
    'historical_events': {
        'test': 'Aluminum-specific events trigger correctly',
        'events': [
            {
                'date': '2009-01-01',
                'event': 'GFC aluminum demand collapse',
                'expected_overlay': 'EXTREME_LOOSE',
                'expected_tightness': '<20'
            },
            {
                'date': '2017-11-01',
                'event': 'China aluminum capacity cuts',
                'expected_overlay': 'EXTREME_TIGHT or TIGHT',
                'expected_tightness': '>70'
            }
        ]
    }
}
```

#### Output Report

```markdown
# Out-of-Sample Metal Test: Aluminum

## Test Configuration
- Metal: LME Aluminum 3-month
- Period: 2000-2025 (25 years)
- Base sleeves: Adapted from copper (same logic, aluminum data)
- Overlays: SAME thresholds as copper (80/20/0.55/1.3)

## Overlay Trigger Frequencies
| Overlay | Copper Freq | Aluminum Freq | Within Range? |
|---------|-------------|---------------|---------------|
| EXTREME_TIGHT | 1.4% | 1.8% | âœ… Yes (1-3%) |
| EXTREME_LOOSE | 1.0% | 1.2% | âœ… Yes (1-3%) |
| HIGH_CHOP | 6.2% | 7.1% | âœ… Yes (5-10%) |
| CRISIS_TIGHT | 2.9% | 2.5% | âœ… Yes (2-5%) |

## Performance Comparison
| Metric | Copper Base | Copper w/Overlays | Aluminum Base | Aluminum w/Overlays |
|--------|-------------|-------------------|---------------|---------------------|
| Sharpe | 0.767 | 0.812 | 0.685 | 0.728 |
| Improvement | - | **+0.045** | - | **+0.043** |
| Max DD | -23.1% | -21.8% | -26.4% | -24.9% |

## Regime-Specific Performance (Aluminum)
| Regime | Base Sharpe | w/Overlays | Improvement |
|--------|-------------|------------|-------------|
| HIGH_CHOP | -0.18 | +0.12 | **+0.30** |
| EXTREME_TIGHT | +0.72 | +0.94 | **+0.22** |
| EXTREME_LOOSE | +0.51 | +0.68 | **+0.17** |

## Historical Event Validation (Aluminum)
âœ… 2009 GFC: EXTREME_LOOSE detected (tight=14)
âœ… 2017 China Capacity Cuts: TIGHT detected (tight=73)
âœ… 2011 Debt Ceiling: CHOP detected (chop=HIGH_CHOP)

## Conclusion
Overlays generalize to aluminum:
- Trigger frequencies appropriate âœ…
- Sharpe improvement similar to copper (+0.043 vs +0.045) âœ…
- Regime-specific improvements consistent âœ…
- Historical events detected correctly âœ…
- Logic NOT copper-specific âœ…

**MAJOR VALIDATION: System works on out-of-sample metal!**

**PASS: Proceed to Test 4B**
```

---

### Test 4B: Random Regime Relabeling Test

#### Purpose
Prove overlay regime classifications aren't arbitrary by showing that random regimes destroy performance.

#### Test Method

```python
def random_relabeling_test(n_permutations=1000):
    """
    1. Take actual backtest data
    2. Randomly permute regime labels
    3. Re-run backtest with permuted regimes
    4. Compare vs actual overlay performance
    """
    
    # Load actual overlay results
    actual_data = load_backtest_with_overlays()
    actual_sharpe = calculate_sharpe(actual_data['returns'])
    baseline_sharpe = calculate_sharpe(actual_data['base_returns'])
    actual_improvement = actual_sharpe - baseline_sharpe
    
    # Run random permutations
    random_improvements = []
    
    for i in range(n_permutations):
        # Permute regime labels
        permuted_data = actual_data.copy()
        permuted_data['chop_regime'] = np.random.permutation(permuted_data['chop_regime'])
        permuted_data['crisis_regime'] = np.random.permutation(permuted_data['crisis_regime'])
        permuted_data['tightness_score'] = np.random.permutation(permuted_data['tightness_score'])
        
        # Recalculate overlays with permuted regimes
        permuted_data['final_position'] = permuted_data.apply(
            lambda row: apply_crisis_directional_overlay(
                base_position=row['base_position'],
                chop_regime=row['chop_regime'],
                crisis_regime=row['crisis_regime'],
                tightness_score=row['tightness_score']
            )[0],
            axis=1
        )
        
        # Calculate permuted returns
        permuted_data['permuted_returns'] = (
            permuted_data['final_position'].shift(1) * 
            permuted_data['price_returns']
        )
        
        # Calculate Sharpe
        permuted_sharpe = calculate_sharpe(permuted_data['permuted_returns'])
        permuted_improvement = permuted_sharpe - baseline_sharpe
        
        random_improvements.append(permuted_improvement)
    
    # Calculate p-value
    # How many random improvements beat actual improvement?
    better_count = sum(1 for x in random_improvements if x > actual_improvement)
    p_value = better_count / n_permutations
    
    return {
        'actual_improvement': actual_improvement,
        'random_mean': np.mean(random_improvements),
        'random_std': np.std(random_improvements),
        'random_max': np.max(random_improvements),
        'p_value': p_value,
        'random_improvements': random_improvements
    }
```

#### Acceptance Criteria

```python
# Test passes if:
acceptance_criteria = {
    'random_destroys_performance': {
        'test': 'Random regimes should hurt, not help',
        'criteria': lambda results: results['random_mean'] < 0,
        'description': 'Mean random improvement should be negative'
    },
    'actual_significantly_better': {
        'test': 'Actual improvement in top 5% of random distribution',
        'criteria': lambda results: results['p_value'] < 0.05,
        'description': 'p<0.05 proves statistical significance'
    },
    'random_never_beats_actual': {
        'test': 'No random permutation beats actual',
        'criteria': lambda results: results['p_value'] == 0,
        'description': 'Strongest evidence of genuine signal'
    }
}
```

#### Output Report

```markdown
# Random Regime Relabeling Test Results

## Test Configuration
- Permutations: 1,000
- Method: Randomly shuffle regime labels, recalculate overlay performance
- Baseline: Sharpe improvement from actual overlays

## Results
| Metric | Value |
|--------|-------|
| Actual Improvement | **+0.045** |
| Random Mean | -0.018 |
| Random Std Dev | 0.008 |
| Random Max | +0.006 |
| Random Min | -0.042 |
| **p-value** | **<0.001** |

## Distribution Analysis
[Histogram showing:]
- Actual improvement: +0.045 (far right tail)
- Random distribution: centered at -0.018 (negative!)
- 95th percentile of random: +0.001
- Actual is beyond 99.9th percentile

## Statistical Significance
âœ… Random regimes DESTROY performance (mean = -0.018)
âœ… Actual improvement far exceeds random maximum (+0.045 vs +0.006)
âœ… p-value <0.001 (highly significant)
âœ… Zero random permutations beat actual (0/1000)

## Conclusion
Overlay regimes are NOT arbitrary:
- Random regimes hurt performance âœ…
- Actual regimes provide genuine signal âœ…
- Statistical significance p<0.001 âœ…
- Proves overlays aren't lucky data-mining âœ…

**PASS: Proceed to Test 4C**
```

---

### Test 4C: Null Hypothesis Testing

#### Purpose
Generate "fake overlays" with random signals at similar frequencies and prove real overlays significantly outperform random noise.

#### Test Method

```python
def generate_fake_overlays(n_fakes=1000):
    """
    Generate fake overlays with same trigger frequency as real overlays.
    """
    
    # Load actual data
    actual_data = load_backtest_with_overlays()
    n_days = len(actual_data)
    
    # Calculate actual trigger frequencies
    extreme_tight_freq = (actual_data['tightness_score'] > 80).sum() / n_days
    high_chop_freq = (actual_data['chop_regime'] == 'HIGH_CHOP').sum() / n_days
    crisis_freq = (actual_data['crisis_regime'].isin(['CRISIS', 'PRE_CRISIS'])).sum() / n_days
    
    fake_results = []
    
    for i in range(n_fakes):
        # Generate random "overlay" signals with same frequency
        fake_data = actual_data.copy()
        
        # Random "extreme tight" days
        fake_extreme_tight = np.random.random(n_days) < extreme_tight_freq
        
        # Random "high chop" days
        fake_high_chop = np.random.random(n_days) < high_chop_freq
        
        # Random "crisis" days
        fake_crisis = np.random.random(n_days) < crisis_freq
        
        # Apply fake overlays with SAME multipliers
        fake_data['fake_position'] = fake_data['base_position'].copy()
        
        # Fake extreme tight: amplify 1.5Ã—
        fake_data.loc[fake_extreme_tight & (fake_data['base_position'] > 0), 
                      'fake_position'] *= 1.5
        
        # Fake high chop: reduce 0.5Ã—
        fake_data.loc[fake_high_chop, 'fake_position'] *= 0.5
        
        # Fake crisis: amplify 1.3Ã—
        fake_data.loc[fake_crisis & (fake_data['base_position'] > 0), 
                      'fake_position'] *= 1.3
        
        # Calculate returns
        fake_data['fake_returns'] = (
            fake_data['fake_position'].shift(1) * 
            fake_data['price_returns']
        )
        
        # Calculate Sharpe
        fake_sharpe = calculate_sharpe(fake_data['fake_returns'])
        baseline_sharpe = calculate_sharpe(fake_data['base_returns'])
        fake_improvement = fake_sharpe - baseline_sharpe
        
        fake_results.append(fake_improvement)
    
    # Compare actual vs fake
    actual_improvement = calculate_sharpe(actual_data['returns']) - baseline_sharpe
    
    # Calculate percentile
    percentile = (sum(1 for x in fake_results if x < actual_improvement) / n_fakes) * 100
    
    return {
        'actual_improvement': actual_improvement,
        'fake_mean': np.mean(fake_results),
        'fake_std': np.std(fake_results),
        'fake_95_percentile': np.percentile(fake_results, 95),
        'actual_percentile': percentile,
        'p_value': (n_fakes - sum(1 for x in fake_results if x < actual_improvement)) / n_fakes
    }
```

#### Acceptance Criteria

```python
# Test passes if:
acceptance_criteria = {
    'actual_beats_95th_percentile': {
        'test': 'Actual improvement exceeds 95th percentile of fakes',
        'criteria': lambda results: results['actual_improvement'] > results['fake_95_percentile'],
        'description': 'Proves genuine value beyond random triggers'
    },
    'p_value_significant': {
        'test': 'p<0.05 for statistical significance',
        'criteria': lambda results: results['p_value'] < 0.05,
        'description': 'Standard statistical significance threshold'
    },
    'large_effect_size': {
        'test': 'Actual improvement at least 2Ã— fake mean (if fake mean positive)',
        'criteria': lambda results: results['actual_improvement'] > max(2 * results['fake_mean'], 0.02),
        'description': 'Large effect size proves practical significance'
    }
}
```

#### Output Report

```markdown
# Null Hypothesis Testing Results

## Test Configuration
- Fake overlays: 1,000 generated
- Method: Random on/off signals at SAME frequency as real overlays
- Multipliers: SAME as real overlays (1.5Ã—, 0.5Ã—, 1.3Ã—)
- Null hypothesis: Real overlays are just lucky random signals

## Results
| Metric | Value |
|--------|-------|
| Actual Improvement | **+0.045** |
| Fake Mean | +0.002 |
| Fake Std Dev | 0.012 |
| Fake 95th Percentile | +0.022 |
| Actual Percentile | **99.2%** |
| **p-value** | **0.008** |

## Distribution Analysis
[Histogram showing:]
- Fake distribution: Roughly normal, centered at +0.002
- 95th percentile: +0.022
- Actual: +0.045 (well above 95th percentile)
- Actual is 3.75 standard deviations above fake mean

## Statistical Tests
âœ… Actual beats 95th percentile (+0.045 vs +0.022)
âœ… p-value <0.05 (p=0.008, statistically significant)
âœ… Large effect size (actual 22.5Ã— fake mean)
âœ… Actual in top 1% of fake distribution

## Interpretation
**Null hypothesis REJECTED:**
- Real overlays provide genuine value, NOT random luck âœ…
- Effect size is large (not just statistically significant) âœ…
- Real overlays ~2Ã— better than best random signals âœ…

**Conclusion:**
Overlays add real alpha beyond random triggering at same frequency.

**PASS: All Phase 4 tests complete**
```

---

## ACCEPTANCE CRITERIA

### Complete System Must Pass ALL Tests

```python
full_system_acceptance = {
    # Phase 1: Individual Overlays
    'chopcore_works': {
        'test': 'ChopCore improves HIGH_CHOP Sharpe by >0.04',
        'result': 'PASS' if chopcore_improvement > 0.04 else 'FAIL'
    },
    'extreme_tightness_works': {
        'test': 'Extreme Tightness triggers correctly on historical events',
        'result': 'PASS' if all_historical_events_detected else 'FAIL'
    },
    'crisis_directional_works': {
        'test': 'CrisisCore provides correct directional amplification',
        'result': 'PASS' if crisis_logic_correct else 'FAIL'
    },
    
    # Phase 2: Combined System
    'priority_hierarchy_correct': {
        'test': 'All 8 priority hierarchy scenarios pass',
        'result': 'PASS' if priority_tests_passed == 8 else 'FAIL'
    },
    'historical_forensics': {
        'test': 'At least 90% of historical events detected correctly',
        'result': 'PASS' if historical_accuracy > 0.90 else 'FAIL'
    },
    
    # Phase 3: Robustness
    'parameter_sensitivity': {
        'test': 'All parameters stable (Â±0.05 Sharpe for Â±5% change)',
        'result': 'PASS' if all_params_stable else 'FAIL'
    },
    'walk_forward': {
        'test': 'Average degradation <20% out-of-sample',
        'result': 'PASS' if avg_degradation < 0.20 else 'FAIL'
    },
    'regime_coverage': {
        'test': 'Dead zones <1% of time',
        'result': 'PASS' if dead_zone_freq < 0.01 else 'FAIL'
    },
    
    # Phase 4: Anti-Bias
    'aluminum_test': {
        'test': 'Overlays generalize to aluminum',
        'result': 'PASS' if aluminum_improvement > 0 else 'FAIL'
    },
    'random_relabeling': {
        'test': 'p<0.05 vs random regime labels',
        'result': 'PASS' if p_value_relabel < 0.05 else 'FAIL'
    },
    'null_hypothesis': {
        'test': 'Actual beats 95th percentile of fake overlays',
        'result': 'PASS' if actual_percentile > 95 else 'FAIL'
    },
    
    # Overall Performance
    'target_sharpe': {
        'test': 'Combined system Sharpe 0.80-0.85',
        'result': 'PASS' if 0.80 <= final_sharpe <= 0.85 else 'WARN'
    },
    'sharpe_improvement': {
        'test': 'Overlays add +0.03 to +0.08 Sharpe',
        'result': 'PASS' if 0.03 <= improvement <= 0.08 else 'WARN'
    }
}
```

### Decision Matrix

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ DEPLOYMENT DECISION MATRIX                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                          â”‚
â”‚ ALL Phase 1-4 Tests Pass:                               â”‚
â”‚   Ã¢â€ ' DEPLOY to live trading immediately                 â”‚
â”‚                                                          â”‚
â”‚ Phase 1-3 Pass, Phase 4 Warning:                        â”‚
â”‚   Ã¢â€ ' DEPLOY with caution, monitor closely               â”‚
â”‚   Ã¢â€ ' Consider position size reduction (50-75%)          â”‚
â”‚                                                          â”‚
â”‚ Any Phase 1-3 Test Fails:                               â”‚
â”‚   Ã¢â€ ' DO NOT DEPLOY                                       â”‚
â”‚   Ã¢â€ ' Investigate failure                                 â”‚
â”‚   Ã¢â€ ' Fix issue, re-run full validation                  â”‚
â”‚                                                          â”‚
â”‚ Phase 4 Fails:                                           â”‚
â”‚   Ã¢â€ ' DO NOT DEPLOY to live capital                      â”‚
â”‚   Ã¢â€ ' Paper trade for 6 months                           â”‚
â”‚   Ã¢â€ ' Re-validate after paper trading period             â”‚
â”‚                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## CODE STRUCTURE

### Recommended Directory Layout

```
C:\Code\Metals\
â”œâ”€â”€ src\
â”‚   â”œâ”€â”€ overlays\
â”‚   â”‚   â”œâ”€â”€ chopcore_overlay.py
â”‚   â”‚   â”œâ”€â”€ tightness_overlay.py
â”‚   â”‚   â”œâ”€â”€ crisis_overlay.py
â”‚   â”‚   â””â”€â”€ priority_hierarchy.py
â”‚   â”‚
â”‚   â”œâ”€â”€ sleeves\
â”‚   â”‚   â”œâ”€â”€ trendcore_v3.py
â”‚   â”‚   â”œâ”€â”€ trendimpulse_v4.py
â”‚   â”‚   â””â”€â”€ momentumcore_v1.py
â”‚   â”‚
â”‚   â”œâ”€â”€ portfolio\
â”‚   â”‚   â””â”€â”€ adaptive_portfolio.py
â”‚   â”‚
â”‚   â””â”€â”€ utils\
â”‚       â”œâ”€â”€ data_loader.py
â”‚       â”œâ”€â”€ metrics.py
â”‚       â””â”€â”€ regime_detector.py
â”‚
â”œâ”€â”€ tests\
â”‚   â”œâ”€â”€ phase1\
â”‚   â”‚   â”œâ”€â”€ test_chopcore_standalone.py
â”‚   â”‚   â”œâ”€â”€ test_tightness_standalone.py
â”‚   â”‚   â””â”€â”€ test_crisis_standalone.py
â”‚   â”‚
â”‚   â”œâ”€â”€ phase2\
â”‚   â”‚   â”œâ”€â”€ test_priority_hierarchy.py
â”‚   â”‚   â””â”€â”€ test_historical_events.py
â”‚   â”‚
â”‚   â”œâ”€â”€ phase3\
â”‚   â”‚   â”œâ”€â”€ test_parameter_sensitivity.py
â”‚   â”‚   â”œâ”€â”€ test_walk_forward.py
â”‚   â”‚   â””â”€â”€ test_regime_coverage.py
â”‚   â”‚
â”‚   â””â”€â”€ phase4\
â”‚       â”œâ”€â”€ test_aluminum.py
â”‚       â”œâ”€â”€ test_random_relabeling.py
â”‚       â””â”€â”€ test_null_hypothesis.py
â”‚
â”œâ”€â”€ scripts\
â”‚   â”œâ”€â”€ build\
â”‚   â”‚   â”œâ”€â”€ build_full_system.py
â”‚   â”‚   â””â”€â”€ build_with_overlays.py
â”‚   â”‚
â”‚   â”œâ”€â”€ test\
â”‚   â”‚   â”œâ”€â”€ run_phase1_tests.bat
â”‚   â”‚   â”œâ”€â”€ run_phase2_tests.bat
â”‚   â”‚   â”œâ”€â”€ run_phase3_tests.bat
â”‚   â”‚   â”œâ”€â”€ run_phase4_tests.bat
â”‚   â”‚   â””â”€â”€ run_full_validation.bat
â”‚   â”‚
â”‚   â””â”€â”€ analysis\
â”‚       â”œâ”€â”€ analyze_results.py
â”‚       â””â”€â”€ generate_reports.py
â”‚
â”œâ”€â”€ Config\
â”‚   â”œâ”€â”€ Copper\
â”‚   â”‚   â”œâ”€â”€ overlays_config.yaml
â”‚   â”‚   â”œâ”€â”€ trendcore_v3.yaml
â”‚   â”‚   â”œâ”€â”€ trendimpulse_v4.yaml
â”‚   â”‚   â””â”€â”€ momentumcore_v1.yaml
â”‚   â”‚
â”‚   â””â”€â”€ Aluminum\
â”‚       â””â”€â”€ overlays_config.yaml
â”‚
â”œâ”€â”€ Data\
â”‚   â”œâ”€â”€ copper\
â”‚   â”‚   â”œâ”€â”€ copper_lme_3mo_canonical.csv
â”‚   â”‚   â”œâ”€â”€ copper_lme_total_stocks_canonical.csv
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚
â”‚   â”œâ”€â”€ aluminum\
â”‚   â”‚   â””â”€â”€ (aluminum data files)
â”‚   â”‚
â”‚   â””â”€â”€ macro\
â”‚       â””â”€â”€ (shared macro data)
â”‚
â”œâ”€â”€ results\
â”‚   â”œâ”€â”€ phase1\
â”‚   â”‚   â”œâ”€â”€ chopcore_results.csv
â”‚   â”‚   â”œâ”€â”€ tightness_results.csv
â”‚   â”‚   â””â”€â”€ crisis_results.csv
â”‚   â”‚
â”‚   â”œâ”€â”€ phase2\
â”‚   â”‚   â”œâ”€â”€ priority_hierarchy_results.csv
â”‚   â”‚   â””â”€â”€ historical_forensics.csv
â”‚   â”‚
â”‚   â”œâ”€â”€ phase3\
â”‚   â”‚   â”œâ”€â”€ sensitivity_analysis.csv
â”‚   â”‚   â”œâ”€â”€ walk_forward_results.csv
â”‚   â”‚   â””â”€â”€ regime_coverage.csv
â”‚   â”‚
â”‚   â””â”€â”€ phase4\
â”‚       â”œâ”€â”€ aluminum_results.csv
â”‚       â”œâ”€â”€ random_relabeling_results.csv
â”‚       â””â”€â”€ null_hypothesis_results.csv
â”‚
â””â”€â”€ reports\
    â”œâ”€â”€ PHASE1_REPORT.md
    â”œâ”€â”€ PHASE2_REPORT.md
    â”œâ”€â”€ PHASE3_REPORT.md
    â”œâ”€â”€ PHASE4_REPORT.md
    â””â”€â”€ FINAL_VALIDATION_SUMMARY.md
```

---

## EXECUTION TIMELINE

### Week 1: Phase 1 - Individual Overlay Validation

**Monday:**
- Set up test framework
- Build `test_chopcore_standalone.py`
- Run ChopCore baseline vs test backtest
- Generate ChopCore report

**Tuesday:**
- Build `test_tightness_standalone.py`
- Run Extreme Tightness tests
- Validate historical events (Grasberg, GFC, etc.)
- Generate Tightness report

**Wednesday:**
- Build `test_crisis_standalone.py`
- Run CrisisCore v2 Directional tests
- Validate crisis + tightness scenarios
- Generate Crisis report

**Thursday:**
- Review all Phase 1 results
- Fix any issues discovered
- Re-run tests if needed

**Friday:**
- Generate Phase 1 summary report
- Decision: Proceed to Phase 2 or iterate?

---

### Week 2: Phase 2 - Combined System Validation

**Monday:**
- Build `test_priority_hierarchy.py`
- Run all 8 priority hierarchy test cases
- Validate mutual exclusivity rules
- Generate hierarchy report

**Tuesday-Wednesday:**
- Build `test_historical_events.py`
- Run forensic analysis on 15 historical events
- Validate overlay triggers for each event
- Document any misses or surprises

**Thursday:**
- Analyze interaction effects
- Check for unintended consequences
- Verify no conflicts between overlays

**Friday:**
- Generate Phase 2 summary report
- Decision: Proceed to Phase 3 or fix issues?

---

### Week 3: Phase 3 - Robustness Testing

**Monday:**
- Build `test_parameter_sensitivity.py`
- Run sensitivity sweeps on all thresholds
- Generate sensitivity charts
- Identify any fragile parameters

**Tuesday-Wednesday:**
- Build `test_walk_forward.py`
- Run 4 walk-forward windows
- Calculate degradation metrics
- Analyze parameter stability

**Thursday:**
- Build `test_regime_coverage.py`
- Analyze regime frequencies
- Identify dead zones
- Assess coverage completeness

**Friday:**
- Generate Phase 3 summary report
- Decision: System robust enough for Phase 4?

---

### Week 4: Phase 4 - Anti-Bias Safeguards

**Monday-Tuesday:**
- Acquire aluminum data
- Build aluminum tightness index
- Build `test_aluminum.py`
- Run full aluminum backtest
- Validate out-of-sample generalization

**Wednesday:**
- Build `test_random_relabeling.py`
- Run 1,000 random permutations
- Calculate p-value
- Prove regimes aren't arbitrary

**Thursday:**
- Build `test_null_hypothesis.py`
- Generate 1,000 fake overlays
- Run null hypothesis test
- Prove genuine alpha vs luck

**Friday:**
- Generate Phase 4 summary report
- Generate FINAL_VALIDATION_SUMMARY.md
- **FINAL DECISION: Deploy or iterate?**

---

### Post-Validation: Deployment Preparation

**Week 5 (if all tests pass):**
- Production hardening
- Real-time data integration
- Position sizing logic
- Risk monitoring dashboard
- Paper trading setup (optional)

---

## APPENDIX: HISTORICAL EVENT CATALOG

### Supply Shock Events (Expected: Extreme Tight)

1. **2006 Grasberg Strike (Jun-Sep)**
   - Event: Freeport mine strike, ~450kt supply lost
   - Expected: EXTREME_TIGHT (>80)
   - Price impact: +30% in 3 months

2. **2010 Codelco Closures (Nov-Feb)**
   - Event: Chile earthquake + multiple mine issues
   - Expected: EXTREME_TIGHT (>80)
   - Price impact: Physical squeeze

3. **2021 Chile Supply Squeeze (May-Aug)**
   - Event: Water restrictions + labor issues
   - Expected: EXTREME_TIGHT (>85)
   - Price impact: Inventory crash to 5-day consumption

### Demand Collapse Events (Expected: Extreme Loose)

4. **2008 GFC (Sep 2008 - Mar 2009)**
   - Event: Lehman collapse, global demand destruction
   - Expected: EXTREME_LOOSE (<15)
   - Price impact: -65% peak-to-trough

5. **2015 China Slowdown (Jul-Dec)**
   - Event: China growth concerns, commodity crash
   - Expected: EXTREME_LOOSE (<20)
   - Price impact: Extended bear market

### Macro Confusion / Chop Events

6. **2018 Trade War (Mar-Nov)**
   - Event: Trump tariffs, tit-for-tat escalation
   - Expected: HIGH_CHOP
   - Price impact: Rangebound, macro cross-currents

7. **2015-2016 Range (Mar 2015 - Jan 2016)**
   - Event: China slowdown fears, ranging market
   - Expected: HIGH_CHOP â†’ EXTREME_LOOSE
   - Price impact: $2.00-2.50 range for months

8. **2011 Debt Ceiling (Aug-Dec)**
   - Event: US debt ceiling drama + Europe debt
   - Expected: MILD_CHOP to HIGH_CHOP
   - Price impact: Choppy, fear vs stabilization

### Crisis + Directional Events

9. **2010 Flash Crash + Europe Debt (May-Sep)**
   - Event: Flash crash + European debt crisis
   - Expected: CRISIS + TIGHT â†’ Amplify bullish
   - Price impact: Crisis but tight fundamentals supported

10. **2016 China Market Crash (Jan-Feb)**
    - Event: China equities crash + oil collapse
    - Expected: CRISIS + LOOSE â†’ Amplify bearish
    - Price impact: Broad commodity selloff

11. **2020 COVID Crash (Mar)**
    - Event: Pandemic lockdowns, demand shock
    - Expected: CRISIS + LOOSE â†’ Amplify bearish
    - Price impact: -25% in 3 weeks

### Normal / Trending Events

12. **2017 Synchronized Growth (Jan-Dec)**
    - Event: Clean global growth, no major shocks
    - Expected: NORMAL operations
    - Price impact: Steady uptrend

13. **2019 Trade Truce (Jan-Dec)**
    - Event: Stable environment, Phase 1 deal
    - Expected: NORMAL to MILD_CHOP
    - Price impact: Rangebound with upward bias

### Mixed / Transition Events

14. **2022 Ukraine War (Jan-Dec)**
    - Event: Ukraine invasion + China COVID zero
    - Expected: MIXED (Crisis vs Chop)
    - Price impact: War premium vs demand destruction

15. **2023-2024 Reopening (Jan 2023 - Jun 2024)**
    - Event: China reopening + banking crisis
    - Expected: MIXED (transition)
    - Price impact: Multiple regime shifts

---

## END OF TESTING PLAN

**Document Version:** 1.0  
**Last Updated:** November 10, 2025  
**Status:** Ready for execution  
**Next Steps:** Begin Phase 1 testing on Monday

**Remember:** This is a comprehensive validation framework. Do not skip steps. Each phase builds on the previous one. If any phase fails, investigate and fix before proceeding.

**Renaissance Principle:** "Test, don't assume. Prove it works before deploying capital."

---